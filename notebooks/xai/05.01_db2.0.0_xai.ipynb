{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-26T15:09:51.038411Z",
     "start_time": "2025-09-26T15:09:51.034963Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "db_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db2.0.0/\"\n",
    "model_dir_root = os.environ[\"DATA\"] + \"models/db2.0.0/\"\n",
    "shap_scale_img_path = os.path.join(db_dir,\"shap_scale.png\")\n",
    "yes_pred_img_path = os.path.join(db_dir,\"button_yes.png\")\n",
    "no_pred_img_path = os.path.join(db_dir,\"button_no.png\")\n",
    "pos_pred_legend_path = os.path.join(db_dir,\"cf_info_pos.png\")\n",
    "neg_pred_legend_path = os.path.join(db_dir,\"cf_info_neg.png\")\n",
    "\n",
    "XAI_DATASET_SIZE = 100\n",
    "N_JOBS = 20\n",
    "N_JOBS_GPU = 6"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T15:09:52.068826Z",
     "start_time": "2025-09-26T15:09:52.066306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of images generated\n",
    "NBGEN = 1000000\n",
    "\n",
    "# Grid division of each image\n",
    "X_DIVISIONS = 6\n",
    "Y_DIVISIONS = 6\n",
    "\n",
    "# Size of the images in pixels\n",
    "img_size = (700, 700)\n",
    "\n",
    "# Probability to generate a geometrical shape at each position in the grid\n",
    "SHAPE_PROB = 0.5\n",
    "\n",
    "# Define available shapes\n",
    "SHAPES = ['circle', 'square', 'triangle']\n",
    "COLORS  = [\"#A33E9A\", \"#E0B000\", \"#0C90C0\"]"
   ],
   "id": "5b67393fc1a2c479",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T15:09:54.606566Z",
     "start_time": "2025-09-26T15:09:53.777933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_exist_row_with_only_shape, generic_rule_N_times_color_exactly, \\\n",
    "    generic_rule_shape_color_plus_shape_equals_N, generic_rule_exist_row_with_only_color_and_col_with_only_shape\n",
    "\n",
    "rules_data = [\n",
    "    {\"name\": \"easy_1_6_blue\", \"gen_fun\": generic_rule_N_times_color_exactly, \"gen_kwargs\": {\"color\": \"#0C90C0\", \"N\": 6, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    {\"name\": \"easy_2_row_circle\", \"gen_fun\": generic_rule_exist_row_with_only_shape, \"gen_kwargs\": {\"shape\": \"circle\", \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"easy_3_7_purple\", \"gen_fun\": generic_rule_N_times_color_exactly, \"gen_kwargs\": {\"color\": \"#A33E9A\", \"N\": 7, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"easy_4_row_triangle\", \"gen_fun\": generic_rule_exist_row_with_only_shape, \"gen_kwargs\": {\"shape\": \"triangle\", \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"easy_5_7_yellow\", \"gen_fun\": generic_rule_N_times_color_exactly, \"gen_kwargs\": {\"color\": \"#E0B000\", \"N\": 5, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"easy_6_row_square\", \"gen_fun\": generic_rule_exist_row_with_only_shape, \"gen_kwargs\": {\"shape\": \"square\", \"y_division\": Y_DIVISIONS}},\n",
    "    #\n",
    "    # {\"name\": \"hard_1_blue_square_plus_circle_8\", \"gen_fun\": generic_rule_shape_color_plus_shape_equals_N, \"gen_kwargs\": {\"color1\": \"#0C90C0\", \"shape1\": \"square\", \"shape2\": \"circle\", \"N\": 8, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"hard_2_row_purple_col_triangle\", \"gen_fun\": generic_rule_exist_row_with_only_color_and_col_with_only_shape, \"gen_kwargs\": {\"color\": \"#A33E9A\", \"shape\": \"triangle\" ,\"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"hard_3_yellow_circle_plus_triangle_9\", \"gen_fun\": generic_rule_shape_color_plus_shape_equals_N, \"gen_kwargs\": {\"color1\": \"#E0B000\", \"shape1\": \"circle\", \"shape2\": \"triangle\", \"N\": 9, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"hard_4_row_yellow_col_circle\", \"gen_fun\": generic_rule_exist_row_with_only_color_and_col_with_only_shape, \"gen_kwargs\": {\"color\": \"#E0B000\", \"shape\": \"circle\" ,\"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"hard_5_purple_triangle_plus_square_7\", \"gen_fun\": generic_rule_shape_color_plus_shape_equals_N, \"gen_kwargs\": {\"color1\": \"#A33E9A\", \"shape1\": \"triangle\", \"shape2\": \"square\", \"N\": 7, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "    # {\"name\": \"hard_6_row_blue_col_square\", \"gen_fun\": generic_rule_exist_row_with_only_color_and_col_with_only_shape, \"gen_kwargs\": {\"color\": \"#0C90C0\", \"shape\": \"square\" ,\"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}},\n",
    "]"
   ],
   "id": "c17bf53f3134ebce",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T15:10:29.295558Z",
     "start_time": "2025-09-26T15:09:55.682557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.dbimg import load_db\n",
    "\n",
    "db = load_db(db_dir)"
   ],
   "id": "fb0bcd9d369ef2ef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T15:11:33.711463Z",
     "start_time": "2025-09-26T15:10:29.397316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.ml.xai import generate_shap_resnet18, generate_counterfactuals_resnet18_random_approach, create_xai_index\n",
    "from tqdm import tqdm\n",
    "\n",
    "for rule_idx in tqdm(range(len(rules_data))):\n",
    "\n",
    "    model_dir = os.path.join(model_dir_root, rules_data[rule_idx][\"name\"])\n",
    "    dataset_filename = rules_data[rule_idx][\"name\"] + \"_test.csv\"\n",
    "\n",
    "    xai_output_paths = {\n",
    "        \"shap\" : \"shap\",\n",
    "        \"cf\" : \"cf\"\n",
    "    }\n",
    "\n",
    "    generate_shap_resnet18(db_dir, dataset_filename=dataset_filename,\n",
    "                           model_dir=model_dir, xai_output_path=os.path.join(model_dir, xai_output_paths[\"shap\"]),\n",
    "                           yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path, device=\"cuda:0\", n_jobs=N_JOBS,\n",
    "                           dataset_size=XAI_DATASET_SIZE, masker=\"ndarray\", shap_scale_img_path=shap_scale_img_path)\n",
    "\n",
    "    generate_counterfactuals_resnet18_random_approach(db_dir, dataset_filename=dataset_filename,\n",
    "                                                      model_dir=model_dir, xai_output_path=os.path.join(model_dir, xai_output_paths[\"cf\"]),\n",
    "                                                      yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path,\n",
    "                                                      shapes=SHAPES, colors=COLORS, empty_probability=1-SHAPE_PROB,\n",
    "                                                      max_depth=10, nb_tries_per_depth=2000, devices=[\"cuda:0\", \"cuda:1\"], n_jobs=N_JOBS_GPU,\n",
    "                                                      dataset_size=XAI_DATASET_SIZE,pos_pred_legend_path=pos_pred_legend_path,\n",
    "                                                      neg_pred_legend_path=neg_pred_legend_path)\n",
    "\n",
    "    create_xai_index(db_dir, dataset_filename=dataset_filename, model_dir=model_dir, xai_dirs=xai_output_paths, dataset_size=XAI_DATASET_SIZE, device=\"cuda:0\")\n"
   ],
   "id": "fb28e1388b0cfcb4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for easy_1_6_blue_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      " 10%|█         | 10/100 [00:00<00:01, 70.42it/s]\u001B[A\n",
      " 18%|█▊        | 18/100 [00:00<00:01, 69.05it/s]\u001B[A\n",
      " 25%|██▌       | 25/100 [00:00<00:01, 65.19it/s]\u001B[A\n",
      " 32%|███▏      | 32/100 [00:00<00:01, 65.06it/s]\u001B[A\n",
      " 39%|███▉      | 39/100 [00:00<00:00, 64.91it/s]\u001B[A\n",
      " 46%|████▌     | 46/100 [00:00<00:00, 56.40it/s]\u001B[A\n",
      " 53%|█████▎    | 53/100 [00:00<00:00, 58.68it/s]\u001B[A\n",
      " 60%|██████    | 60/100 [00:00<00:00, 61.18it/s]\u001B[A\n",
      " 67%|██████▋   | 67/100 [00:01<00:00, 62.51it/s]\u001B[A\n",
      " 74%|███████▍  | 74/100 [00:01<00:00, 61.81it/s]\u001B[A\n",
      " 81%|████████  | 81/100 [00:01<00:00, 62.65it/s]\u001B[A\n",
      " 88%|████████▊ | 88/100 [00:01<00:00, 56.01it/s]\u001B[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.80it/s][A\n",
      "Using cache found in /home/docker/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing shap values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9998 [00:00<?, ?it/s]\u001B[A\n",
      " 18%|█▊        | 1842/9998 [00:00<00:00, 13105.02it/s]\u001B[A\n",
      " 32%|███▏      | 3192/9998 [00:03<00:10, 674.82it/s]  \u001B[A\n",
      " 38%|███▊      | 3792/9998 [00:05<00:11, 549.82it/s]\u001B[A\n",
      " 41%|████▏     | 4142/9998 [00:06<00:11, 501.78it/s]\u001B[A\n",
      " 44%|████▍     | 4392/9998 [00:07<00:11, 471.68it/s]\u001B[A\n",
      " 45%|████▌     | 4542/9998 [00:07<00:12, 453.92it/s]\u001B[A\n",
      " 47%|████▋     | 4692/9998 [00:08<00:12, 435.57it/s]\u001B[A\n",
      " 48%|████▊     | 4792/9998 [00:08<00:12, 423.95it/s]\u001B[A\n",
      " 49%|████▉     | 4892/9998 [00:08<00:12, 410.99it/s]\u001B[A\n",
      " 50%|████▉     | 4992/9998 [00:09<00:12, 395.73it/s]\u001B[A\n",
      " 51%|█████     | 5092/9998 [00:09<00:12, 386.27it/s]\u001B[A\n",
      " 51%|█████▏    | 5142/9998 [00:09<00:12, 380.84it/s]\u001B[A\n",
      " 52%|█████▏    | 5192/9998 [00:09<00:12, 375.88it/s]\u001B[A\n",
      " 52%|█████▏    | 5242/9998 [00:09<00:12, 370.16it/s]\u001B[A\n",
      " 53%|█████▎    | 5292/9998 [00:09<00:12, 365.86it/s]\u001B[A\n",
      " 53%|█████▎    | 5342/9998 [00:10<00:12, 361.76it/s]\u001B[A\n",
      " 54%|█████▍    | 5392/9998 [00:10<00:12, 358.67it/s]\u001B[A\n",
      " 54%|█████▍    | 5442/9998 [00:10<00:12, 355.46it/s]\u001B[A\n",
      " 55%|█████▍    | 5492/9998 [00:10<00:12, 353.22it/s]\u001B[A\n",
      " 55%|█████▌    | 5542/9998 [00:10<00:12, 350.56it/s]\u001B[A\n",
      " 56%|█████▌    | 5592/9998 [00:10<00:12, 341.51it/s]\u001B[A\n",
      " 56%|█████▋    | 5642/9998 [00:10<00:12, 342.36it/s]\u001B[A\n",
      " 57%|█████▋    | 5692/9998 [00:11<00:12, 342.69it/s]\u001B[A\n",
      " 57%|█████▋    | 5742/9998 [00:11<00:12, 344.16it/s]\u001B[A\n",
      " 58%|█████▊    | 5792/9998 [00:11<00:12, 346.19it/s]\u001B[A\n",
      " 58%|█████▊    | 5842/9998 [00:11<00:11, 347.61it/s]\u001B[A\n",
      " 59%|█████▉    | 5892/9998 [00:11<00:11, 349.31it/s]\u001B[A\n",
      " 59%|█████▉    | 5942/9998 [00:11<00:11, 349.25it/s]\u001B[A\n",
      "  0%|          | 0/2 [00:27<?, ?it/s]11, 349.08it/s]\u001B[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 14\u001B[0m\n\u001B[1;32m      7\u001B[0m dataset_filename \u001B[38;5;241m=\u001B[39m rules_data[rule_idx][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_test.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m xai_output_paths \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshap\u001B[39m\u001B[38;5;124m\"\u001B[39m : \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcf\u001B[39m\u001B[38;5;124m\"\u001B[39m : \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     12\u001B[0m }\n\u001B[0;32m---> 14\u001B[0m generate_shap_resnet18(db_dir, dataset_filename\u001B[38;5;241m=\u001B[39mdataset_filename,\n\u001B[1;32m     15\u001B[0m                        model_dir\u001B[38;5;241m=\u001B[39mmodel_dir, xai_output_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_dir, xai_output_paths[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshap\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[1;32m     16\u001B[0m                        yes_pred_img_path\u001B[38;5;241m=\u001B[39myes_pred_img_path, no_pred_img_path\u001B[38;5;241m=\u001B[39mno_pred_img_path, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m\"\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39mN_JOBS,\n\u001B[1;32m     17\u001B[0m                        dataset_size\u001B[38;5;241m=\u001B[39mXAI_DATASET_SIZE, masker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndarray\u001B[39m\u001B[38;5;124m\"\u001B[39m, shap_scale_img_path\u001B[38;5;241m=\u001B[39mshap_scale_img_path)\n\u001B[1;32m     19\u001B[0m generate_counterfactuals_resnet18_random_approach(db_dir, dataset_filename\u001B[38;5;241m=\u001B[39mdataset_filename,\n\u001B[1;32m     20\u001B[0m                                                   model_dir\u001B[38;5;241m=\u001B[39mmodel_dir, xai_output_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_dir, xai_output_paths[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcf\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[1;32m     21\u001B[0m                                                   yes_pred_img_path\u001B[38;5;241m=\u001B[39myes_pred_img_path, no_pred_img_path\u001B[38;5;241m=\u001B[39mno_pred_img_path,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     24\u001B[0m                                                   dataset_size\u001B[38;5;241m=\u001B[39mXAI_DATASET_SIZE,pos_pred_legend_path\u001B[38;5;241m=\u001B[39mpos_pred_legend_path,\n\u001B[1;32m     25\u001B[0m                                                   neg_pred_legend_path\u001B[38;5;241m=\u001B[39mneg_pred_legend_path)\n\u001B[1;32m     27\u001B[0m create_xai_index(db_dir, dataset_filename\u001B[38;5;241m=\u001B[39mdataset_filename, model_dir\u001B[38;5;241m=\u001B[39mmodel_dir, xai_dirs\u001B[38;5;241m=\u001B[39mxai_output_paths, dataset_size\u001B[38;5;241m=\u001B[39mXAI_DATASET_SIZE, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/git_repos/xaipatimg/xaipatimg/ml/xai.py:393\u001B[0m, in \u001B[0;36mgenerate_shap_resnet18\u001B[0;34m(db_dir, dataset_filename, model_dir, xai_output_path, yes_pred_img_path, no_pred_img_path, device, n_jobs, dataset_size, masker, shap_scale_img_path)\u001B[0m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComputing shap values\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    392\u001B[0m explainer \u001B[38;5;241m=\u001B[39m shap\u001B[38;5;241m.\u001B[39mExplainer(predict, masker\u001B[38;5;241m=\u001B[39mmasker_f, output_names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 393\u001B[0m shap_values \u001B[38;5;241m=\u001B[39m explainer(\n\u001B[1;32m    394\u001B[0m     Xtr, max_evals\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m\n\u001B[1;32m    395\u001B[0m )\n\u001B[1;32m    396\u001B[0m min_shap_value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(shap_values\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m    397\u001B[0m max_shap_value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(shap_values\u001B[38;5;241m.\u001B[39mvalues)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/explainers/_partition.py:173\u001B[0m, in \u001B[0;36mPartitionExplainer.__call__\u001B[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;241m*\u001B[39margs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    170\u001B[0m     silent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    171\u001B[0m ):\n\u001B[1;32m    172\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    174\u001B[0m         \u001B[38;5;241m*\u001B[39margs,\n\u001B[1;32m    175\u001B[0m         max_evals\u001B[38;5;241m=\u001B[39mmax_evals,\n\u001B[1;32m    176\u001B[0m         fixed_context\u001B[38;5;241m=\u001B[39mfixed_context,\n\u001B[1;32m    177\u001B[0m         main_effects\u001B[38;5;241m=\u001B[39mmain_effects,\n\u001B[1;32m    178\u001B[0m         error_bounds\u001B[38;5;241m=\u001B[39merror_bounds,\n\u001B[1;32m    179\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m    180\u001B[0m         outputs\u001B[38;5;241m=\u001B[39moutputs,\n\u001B[1;32m    181\u001B[0m         silent\u001B[38;5;241m=\u001B[39msilent,\n\u001B[1;32m    182\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/explainers/_explainer.py:366\u001B[0m, in \u001B[0;36mExplainer.__call__\u001B[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001B[0m\n\u001B[1;32m    364\u001B[0m     feature_names \u001B[38;5;241m=\u001B[39m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(args))]\n\u001B[1;32m    365\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row_args \u001B[38;5;129;01min\u001B[39;00m show_progress(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39margs), num_rows, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m explainer\u001B[39m\u001B[38;5;124m\"\u001B[39m, silent):\n\u001B[0;32m--> 366\u001B[0m     row_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplain_row(\n\u001B[1;32m    367\u001B[0m         \u001B[38;5;241m*\u001B[39mrow_args,\n\u001B[1;32m    368\u001B[0m         max_evals\u001B[38;5;241m=\u001B[39mmax_evals,\n\u001B[1;32m    369\u001B[0m         main_effects\u001B[38;5;241m=\u001B[39mmain_effects,\n\u001B[1;32m    370\u001B[0m         error_bounds\u001B[38;5;241m=\u001B[39merror_bounds,\n\u001B[1;32m    371\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m    372\u001B[0m         outputs\u001B[38;5;241m=\u001B[39moutputs,\n\u001B[1;32m    373\u001B[0m         silent\u001B[38;5;241m=\u001B[39msilent,\n\u001B[1;32m    374\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    375\u001B[0m     )\n\u001B[1;32m    376\u001B[0m     values\u001B[38;5;241m.\u001B[39mappend(row_result\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    377\u001B[0m     output_indices\u001B[38;5;241m.\u001B[39mappend(row_result\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/explainers/_partition.py:229\u001B[0m, in \u001B[0;36mPartitionExplainer.explain_row\u001B[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(out_shape)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdvalues \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(out_shape)\n\u001B[0;32m--> 229\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mowen(fm, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_curr_base_value, f11, max_evals \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m2\u001B[39m, outputs, fixed_context, batch_size, silent)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;66;03m# if False:\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;66;03m#     if self.multi_output:\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;66;03m#         return [self.dvalues[:,i] for i in range(self.dvalues.shape[1])], oinds\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;66;03m# else:\u001B[39;00m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# drop the interaction terms down onto self.values\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues[:] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdvalues\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/explainers/_partition.py:339\u001B[0m, in \u001B[0;36mPartitionExplainer.owen\u001B[0;34m(self, fm, f00, f11, max_evals, output_indexes, fixed_context, batch_size, silent)\u001B[0m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;66;03m# run the batch\u001B[39;00m\n\u001B[1;32m    338\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(batch_args) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 339\u001B[0m     fout \u001B[38;5;241m=\u001B[39m fm(batch_masks)\n\u001B[1;32m    340\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_indexes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    341\u001B[0m         fout \u001B[38;5;241m=\u001B[39m fout[:, output_indexes]\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/utils/_masked_model.py:67\u001B[0m, in \u001B[0;36mMaskedModel.__call__\u001B[0;34m(self, masks, zero_index, batch_size)\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_full_masking_call(full_masks, zero_index\u001B[38;5;241m=\u001B[39mzero_index, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_full_masking_call(masks, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/utils/_masked_model.py:142\u001B[0m, in \u001B[0;36mMaskedModel._full_masking_call\u001B[0;34m(self, masks, zero_index, batch_size)\u001B[0m\n\u001B[1;32m    139\u001B[0m         all_masked_inputs[i]\u001B[38;5;241m.\u001B[39mappend(v)\n\u001B[1;32m    141\u001B[0m joined_masked_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m([np\u001B[38;5;241m.\u001B[39mconcatenate(v) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m all_masked_inputs])\n\u001B[0;32m--> 142\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39mjoined_masked_inputs)\n\u001B[1;32m    143\u001B[0m _assert_output_input_match(joined_masked_inputs, outputs)\n\u001B[1;32m    144\u001B[0m all_outputs\u001B[38;5;241m.\u001B[39mappend(outputs)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/models/_model.py:25\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m     23\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minner_model(\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m     24\u001B[0m is_tensor \u001B[38;5;241m=\u001B[39m safe_isinstance(out, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.Tensor\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 25\u001B[0m out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy() \u001B[38;5;28;01mif\u001B[39;00m is_tensor \u001B[38;5;28;01melse\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(out)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "id": "381e2ac75e35913f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c418ac7342c2bf59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1f2b46b2badd40d5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
