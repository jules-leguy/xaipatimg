{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-09T22:02:01.493500Z",
     "start_time": "2025-11-09T22:02:01.490616Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "db_S_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0_S/\"\n",
    "db_L_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0_L/\"\n",
    "db_M_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0_M/\"\n",
    "db_patterns_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0/patterns/\"\n",
    "\n",
    "\n",
    "model_dir_root = os.environ[\"DATA\"] + \"models/db3.0.0/01_protov5/\"\n",
    "shap_scale_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0\",\"shap_scale.png\")\n",
    "yes_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0\",\"button_yes.png\")\n",
    "no_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0\",\"button_no.png\")\n",
    "yes_small_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0\",\"button_yes_small.png\")\n",
    "no_small_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0\",\"button_no_small.png\")\n",
    "pos_pred_legend_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0\",\"cf_info_pos.png\")\n",
    "neg_pred_legend_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.0.0\",\"cf_info_neg.png\")\n",
    "interface_dir = os.environ[\"DATA\"] + \"webinterfaces/int05_prototype/\"\n",
    "\n",
    "XAI_DATASET_SIZE = 50\n",
    "\n",
    "N_JOBS = 20\n",
    "N_JOBS_GPU = 6"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:02:01.974621Z",
     "start_time": "2025-11-09T22:02:01.971887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Grid division for full image\n",
    "X_DIVISIONS_L = 15\n",
    "Y_DIVISIONS_L = 15\n",
    "X_DIVISIONS_S = 10\n",
    "Y_DIVISIONS_S = 10\n",
    "\n",
    "# Grid division of patterns\n",
    "X_DIVISIONS_PATTERNS = 2\n",
    "Y_DIVISIONS_PATTERNS = 2\n",
    "\n",
    "# Probability to generate a geometrical shape at each position in the grid\n",
    "SHAPE_PROB = 0.5\n",
    "\n",
    "# Define available shapes\n",
    "SHAPES = ['circle', 'square', 'triangle']\n",
    "COLORS  = [\"#A33E9A\", \"#E0B000\", \"#0C90C0\"] # Purple, Yellow, Blue\n",
    "\n",
    "explict_colors_dict = {\n",
    "    \"#A33E9A\": \"purple\",\n",
    "    \"#E0B000\": \"yellow\",\n",
    "    \"#0C90C0\": \"blue\"\n",
    "}"
   ],
   "id": "5b67393fc1a2c479",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:02:02.728214Z",
     "start_time": "2025-11-09T22:02:02.725280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.dbimg import load_db\n",
    "\n",
    "db_patterns = load_db(db_patterns_dir)"
   ],
   "id": "e1ffb9995502154e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:02:12.271177Z",
     "start_time": "2025-11-09T22:02:12.268465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pattern_3sym_2col_keys = []\n",
    "\n",
    "# Extracting list of patterns that contain 3 symbols and 2 colors\n",
    "for k, v in db_patterns.items():\n",
    "    if len(v[\"content\"]) == 3:\n",
    "        img_col_d = {}\n",
    "        for entry in v[\"content\"]:\n",
    "            img_col_d[entry[\"color\"]] = True\n",
    "\n",
    "        if len(img_col_d.keys()) == 2:\n",
    "            pattern_3sym_2col_keys.append(k)"
   ],
   "id": "2e52048889c4dd06",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:02:12.711315Z",
     "start_time": "2025-11-09T22:02:12.709431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets_path_L = os.path.join(db_L_dir, \"datasets\", \"01_protov5\")\n",
    "datasets_path_S = os.path.join(db_S_dir, \"datasets\", \"01_protov5\")\n",
    "datasets_path_M = os.path.join(db_M_dir, \"datasets\", \"01_protov5\")"
   ],
   "id": "e3bad93fe4bc7d0d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:02:14.849353Z",
     "start_time": "2025-11-09T22:02:14.461912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_pattern_exactly_1_time_exclude_more, \\\n",
    "    generic_rule_shape_color_even\n",
    "\n",
    "rules_data_L = [\n",
    "\n",
    "    {\"name\": \"hard1_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_L,\n",
    "                                                                                                     \"y_division_full\": Y_DIVISIONS_L,\n",
    "                                                                                                     \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[0]},\n",
    "\n",
    "    {\"name\": \"hard2_blue_circle_even\", \"gen_fun\": generic_rule_shape_color_even, \"gen_kwargs\": {\"x_division\": X_DIVISIONS_L,\n",
    "                                                                                                \"y_division\": Y_DIVISIONS_L,\n",
    "                                                                                                \"shape\": \"circle\",\n",
    "                                                                                                \"color\": \"#0C90C0\"},\n",
    "     \"question\": \"Is the number of blue circles an even number?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\"},\n",
    "\n",
    "    {\"name\": \"hard3_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_L,\n",
    "                                                                                                     \"y_division_full\": Y_DIVISIONS_L,\n",
    "                                                                                                     \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[1]},\n",
    "\n",
    "    {\"name\": \"hard4_purple_square_even\", \"gen_fun\": generic_rule_shape_color_even, \"gen_kwargs\": {\"x_division\": X_DIVISIONS_L,\n",
    "                                                                                                \"y_division\": Y_DIVISIONS_L,\n",
    "                                                                                                \"shape\": \"square\",\n",
    "                                                                                                \"color\": \"#A33E9A\"},\n",
    "     \"question\": \"Is the number of purple squares an even number?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\"},\n",
    "]"
   ],
   "id": "c17bf53f3134ebce",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:02:14.964883Z",
     "start_time": "2025-11-09T22:02:14.961646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_pattern_exactly_1_time_exclude_more, \\\n",
    "    generic_rule_shape_color_even\n",
    "\n",
    "rules_data_S = [\n",
    "\n",
    "    {\"name\": \"easy1_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_S,\n",
    "                                                                                                     \"y_division_full\": Y_DIVISIONS_S,\n",
    "                                                                                                     \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[2]},\n",
    "\n",
    "    {\"name\": \"easy2_yellow_triangle_even\", \"gen_fun\": generic_rule_shape_color_even, \"gen_kwargs\": {\"x_division\": X_DIVISIONS_S,\n",
    "                                                                                                \"y_division\": Y_DIVISIONS_S,\n",
    "                                                                                                \"shape\": \"triangle\",\n",
    "                                                                                                \"color\": \"#E0B000\"},\n",
    "     \"question\": \"Is the number of yellow triangles an even number?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\"},\n",
    "\n",
    "    {\"name\": \"easy3_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_S,\n",
    "                                                                                                     \"y_division_full\": Y_DIVISIONS_S,\n",
    "                                                                                                     \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[3]},\n",
    "\n",
    "    {\"name\": \"easy4_purple_circle_even\", \"gen_fun\": generic_rule_shape_color_even, \"gen_kwargs\": {\"x_division\": X_DIVISIONS_S,\n",
    "                                                                                                  \"y_division\": Y_DIVISIONS_S,\n",
    "                                                                                                  \"shape\": \"circle\",\n",
    "                                                                                                  \"color\": \"#A33E9A\"},\n",
    "     \"question\": \"Is the number of purple circles an even number?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\"},\n",
    "]"
   ],
   "id": "1d586bf25ec0f176",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:24:10.915851Z",
     "start_time": "2025-11-09T22:24:10.911695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_pattern_exactly_1_time_exclude_more, \\\n",
    "    generic_rule_shape_color_even\n",
    "\n",
    "rules_data_M = [\n",
    "\n",
    "    {\"name\": \"med1_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_L,\n",
    "                                                                                                     \"y_division_full\": Y_DIVISIONS_L,\n",
    "                                                                                                     \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[4]},\n",
    "\n",
    "    {\"name\": \"med2_yellow_square_even\", \"gen_fun\": generic_rule_shape_color_even, \"gen_kwargs\": {\"x_division\": X_DIVISIONS_L,\n",
    "                                                                                                \"y_division\": Y_DIVISIONS_L,\n",
    "                                                                                                \"shape\": \"square\",\n",
    "                                                                                                \"color\": \"#E0B000\"},\n",
    "     \"question\": \"Is the number of yellow squares an even number?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\"},\n",
    "\n",
    "    {\"name\": \"med3_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_L,\n",
    "                                                                                                     \"y_division_full\": Y_DIVISIONS_L,\n",
    "                                                                                                     \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                     \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[5]},\n",
    "\n",
    "    {\"name\": \"med4_blue_triangle_even\", \"gen_fun\": generic_rule_shape_color_even, \"gen_kwargs\": {\"x_division\": X_DIVISIONS_L,\n",
    "                                                                                                \"y_division\": Y_DIVISIONS_L,\n",
    "                                                                                                \"shape\": \"triangle\",\n",
    "                                                                                                \"color\": \"#0C90C0\"},\n",
    "     \"question\": \"Is the number of blue triangles an even number?\", \"target_acc\" : 0.1, \"shown_acc\" : 0.9, \"samples_interface\": 10, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\"},\n",
    "]"
   ],
   "id": "4bdf931ea82c344e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:24:11.228237Z",
     "start_time": "2025-11-09T22:24:11.224899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.ml.xai import generate_shap_resnet18, generate_counterfactuals_resnet18_random_approach, \\\n",
    "    create_xai_index\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_explanations(rules_data, db_dir, datasets_dir_path):\n",
    "\n",
    "    for rule_idx in tqdm(range(len(rules_data))):\n",
    "\n",
    "        model_dir = os.path.join(model_dir_root, rules_data[rule_idx][\"name\"])\n",
    "        dataset_filename = rules_data[rule_idx][\"name\"] + \"_test.csv\"\n",
    "        generic_rule_fun = rules_data[rule_idx][\"gen_fun\"]\n",
    "        generic_rule_fun_kwargs = rules_data[rule_idx][\"gen_kwargs\"]\n",
    "        xai_output_paths = {\n",
    "            \"shap\" : \"shap\",\n",
    "            # \"cf\" : \"cf\",\n",
    "        }\n",
    "\n",
    "        if \"pattern_id\" in rules_data[rule_idx]:\n",
    "            generic_rule_fun_kwargs[\"pattern_content\"] = db_patterns[rules_data[rule_idx][\"pattern_id\"]][\"content\"]\n",
    "\n",
    "        generate_shap_resnet18(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "                               model_dir=model_dir, xai_output_path=os.path.join(model_dir, xai_output_paths[\"shap\"]),\n",
    "                               yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path, device=\"cuda:0\", n_jobs=N_JOBS,\n",
    "                               dataset_size=XAI_DATASET_SIZE, masker=\"ndarray\", shap_scale_img_path=shap_scale_img_path, max_evals=3)\n",
    "\n",
    "        # generate_counterfactuals_resnet18_random_approach(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "        #                                                   model_dir=model_dir,\n",
    "        #                                                   xai_output_path=os.path.join(model_dir, xai_output_paths[\"cf\"]),\n",
    "        #                                                   yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path,\n",
    "        #                                                   shapes=SHAPES, colors=COLORS, empty_probability=1-SHAPE_PROB,\n",
    "        #                                                   max_depth=10, nb_tries_per_depth=2000, generic_rule_fun=generic_rule_fun,\n",
    "        #                                                   devices=[\"cuda:0\", \"cuda:1\"], n_jobs=N_JOBS_GPU,\n",
    "        #                                                   dataset_size=XAI_DATASET_SIZE,pos_pred_legend_path=pos_pred_legend_path,\n",
    "        #                                                   neg_pred_legend_path=neg_pred_legend_path,\n",
    "        #                                                   **generic_rule_fun_kwargs)\n",
    "\n",
    "        create_xai_index(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename, model_dir=model_dir,\n",
    "                         xai_dirs=xai_output_paths, dataset_size=XAI_DATASET_SIZE, device=\"cuda:0\")\n"
   ],
   "id": "381e2ac75e35913f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:24:16.834198Z",
     "start_time": "2025-11-09T22:24:11.823934Z"
    }
   },
   "cell_type": "code",
   "source": "generate_explanations(rules_data_S, db_S_dir, datasets_path_S)",
   "id": "a6be4c5a0e01802c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for easy1_find_pattern_rot_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 34%|███▍      | 17/50 [00:00<00:00, 167.77it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 144.19it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing shap values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m generate_explanations(rules_data_S, db_S_dir, datasets_path_S)\n",
      "Cell \u001B[0;32mIn[14], line 21\u001B[0m, in \u001B[0;36mgenerate_explanations\u001B[0;34m(rules_data, db_dir, datasets_dir_path)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpattern_id\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m rules_data[rule_idx]:\n\u001B[1;32m     19\u001B[0m     generic_rule_fun_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpattern_content\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m db_patterns[rules_data[rule_idx][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpattern_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m---> 21\u001B[0m generate_shap_resnet18(db_dir, datasets_dir_path\u001B[38;5;241m=\u001B[39mdatasets_dir_path, dataset_filename\u001B[38;5;241m=\u001B[39mdataset_filename,\n\u001B[1;32m     22\u001B[0m                        model_dir\u001B[38;5;241m=\u001B[39mmodel_dir, xai_output_path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_dir, xai_output_paths[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshap\u001B[39m\u001B[38;5;124m\"\u001B[39m]),\n\u001B[1;32m     23\u001B[0m                        yes_pred_img_path\u001B[38;5;241m=\u001B[39myes_pred_img_path, no_pred_img_path\u001B[38;5;241m=\u001B[39mno_pred_img_path, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m\"\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39mN_JOBS,\n\u001B[1;32m     24\u001B[0m                        dataset_size\u001B[38;5;241m=\u001B[39mXAI_DATASET_SIZE, masker\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndarray\u001B[39m\u001B[38;5;124m\"\u001B[39m, shap_scale_img_path\u001B[38;5;241m=\u001B[39mshap_scale_img_path, max_evals\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# generate_counterfactuals_resnet18_random_approach(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m#                                                   model_dir=model_dir,\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m#                                                   xai_output_path=os.path.join(model_dir, xai_output_paths[\"cf\"]),\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m#                                                   neg_pred_legend_path=neg_pred_legend_path,\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m#                                                   **generic_rule_fun_kwargs)\u001B[39;00m\n\u001B[1;32m     37\u001B[0m create_xai_index(db_dir, datasets_dir_path\u001B[38;5;241m=\u001B[39mdatasets_dir_path, dataset_filename\u001B[38;5;241m=\u001B[39mdataset_filename, model_dir\u001B[38;5;241m=\u001B[39mmodel_dir,\n\u001B[1;32m     38\u001B[0m                  xai_dirs\u001B[38;5;241m=\u001B[39mxai_output_paths, dataset_size\u001B[38;5;241m=\u001B[39mXAI_DATASET_SIZE, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda:0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/postdoc/git_repos/xaipatimg/xaipatimg/ml/xai.py:403\u001B[0m, in \u001B[0;36mgenerate_shap_resnet18\u001B[0;34m(db_dir, datasets_dir_path, dataset_filename, model_dir, xai_output_path, yes_pred_img_path, no_pred_img_path, device, n_jobs, dataset_size, masker, shap_scale_img_path, max_evals)\u001B[0m\n\u001B[1;32m    401\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComputing shap values\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    402\u001B[0m explainer \u001B[38;5;241m=\u001B[39m shap\u001B[38;5;241m.\u001B[39mExplainer(predict, masker\u001B[38;5;241m=\u001B[39mmasker_f, output_names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 403\u001B[0m shap_values \u001B[38;5;241m=\u001B[39m explainer(\n\u001B[1;32m    404\u001B[0m     Xtr, max_evals\u001B[38;5;241m=\u001B[39mmax_evals, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m\n\u001B[1;32m    405\u001B[0m )\n\u001B[1;32m    406\u001B[0m min_shap_value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(shap_values\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[1;32m    407\u001B[0m max_shap_value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(shap_values\u001B[38;5;241m.\u001B[39mvalues)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/explainers/_partition.py:128\u001B[0m, in \u001B[0;36mPartitionExplainer.__call__\u001B[0;34m(self, max_evals, fixed_context, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, max_evals\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m, fixed_context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, main_effects\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, error_bounds\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    126\u001B[0m              outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, silent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    127\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;241m*\u001B[39margs, max_evals\u001B[38;5;241m=\u001B[39mmax_evals, fixed_context\u001B[38;5;241m=\u001B[39mfixed_context, main_effects\u001B[38;5;241m=\u001B[39mmain_effects, error_bounds\u001B[38;5;241m=\u001B[39merror_bounds, batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m    130\u001B[0m         outputs\u001B[38;5;241m=\u001B[39moutputs, silent\u001B[38;5;241m=\u001B[39msilent\n\u001B[1;32m    131\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/explainers/_explainer.py:266\u001B[0m, in \u001B[0;36mExplainer.__call__\u001B[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001B[0m\n\u001B[1;32m    264\u001B[0m     feature_names \u001B[38;5;241m=\u001B[39m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(args))]\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row_args \u001B[38;5;129;01min\u001B[39;00m show_progress(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39margs), num_rows, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m explainer\u001B[39m\u001B[38;5;124m\"\u001B[39m, silent):\n\u001B[0;32m--> 266\u001B[0m     row_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplain_row(\n\u001B[1;32m    267\u001B[0m         \u001B[38;5;241m*\u001B[39mrow_args, max_evals\u001B[38;5;241m=\u001B[39mmax_evals, main_effects\u001B[38;5;241m=\u001B[39mmain_effects, error_bounds\u001B[38;5;241m=\u001B[39merror_bounds,\n\u001B[1;32m    268\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size, outputs\u001B[38;5;241m=\u001B[39moutputs, silent\u001B[38;5;241m=\u001B[39msilent, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    269\u001B[0m     )\n\u001B[1;32m    270\u001B[0m     values\u001B[38;5;241m.\u001B[39mappend(row_result\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    271\u001B[0m     output_indices\u001B[38;5;241m.\u001B[39mappend(row_result\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_indices\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/explainers/_partition.py:151\u001B[0m, in \u001B[0;36mPartitionExplainer.explain_row\u001B[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, fixed_context, *row_args)\u001B[0m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;66;03m# if not fixed background or no base value assigned then compute base value for a row\u001B[39;00m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_curr_base_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasker, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfixed_background\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 151\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_curr_base_value \u001B[38;5;241m=\u001B[39m fm(m00\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m), zero_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;66;03m# the zero index param tells the masked model what the baseline is\u001B[39;00m\n\u001B[1;32m    152\u001B[0m f11 \u001B[38;5;241m=\u001B[39m fm(\u001B[38;5;241m~\u001B[39mm00\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasker\u001B[38;5;241m.\u001B[39mclustering):\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/utils/_masked_model.py:70\u001B[0m, in \u001B[0;36mMaskedModel.__call__\u001B[0;34m(self, masks, zero_index, batch_size)\u001B[0m\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_full_masking_call(full_masks, zero_index\u001B[38;5;241m=\u001B[39mzero_index, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_full_masking_call(masks, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/utils/_masked_model.py:161\u001B[0m, in \u001B[0;36mMaskedModel._full_masking_call\u001B[0;34m(self, masks, zero_index, batch_size)\u001B[0m\n\u001B[1;32m    158\u001B[0m last_outs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((max_outs,) \u001B[38;5;241m+\u001B[39m outputs\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m:])\n\u001B[1;32m    159\u001B[0m varying_rows \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(varying_rows)\n\u001B[0;32m--> 161\u001B[0m _build_fixed_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlink, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_linearizing_weights)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m averaged_outs\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/shap/utils/_masked_model.py:385\u001B[0m, in \u001B[0;36m_build_fixed_output\u001B[0;34m(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights)\u001B[0m\n\u001B[1;32m    376\u001B[0m     _build_fixed_single_output(_upcast_array(averaged_outs),\n\u001B[1;32m    377\u001B[0m                                _upcast_array(last_outs),\n\u001B[1;32m    378\u001B[0m                                _upcast_array(outputs),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    382\u001B[0m                                link,\n\u001B[1;32m    383\u001B[0m                                linearizing_weights)\n\u001B[1;32m    384\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 385\u001B[0m     _build_fixed_multi_output(_upcast_array(averaged_outs),\n\u001B[1;32m    386\u001B[0m                               _upcast_array(last_outs),\n\u001B[1;32m    387\u001B[0m                               _upcast_array(outputs),\n\u001B[1;32m    388\u001B[0m                               batch_positions,\n\u001B[1;32m    389\u001B[0m                               varying_rows,\n\u001B[1;32m    390\u001B[0m                               num_varying_rows,\n\u001B[1;32m    391\u001B[0m                               link,\n\u001B[1;32m    392\u001B[0m                               linearizing_weights)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/dispatcher.py:376\u001B[0m, in \u001B[0;36m_DispatcherBase._compile_for_args\u001B[0;34m(self, *args, **kws)\u001B[0m\n\u001B[1;32m    374\u001B[0m return_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     return_val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;28mtuple\u001B[39m(argtypes))\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mForceLiteralArg \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;66;03m# Received request for compiler re-entry with the list of arguments\u001B[39;00m\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;66;03m# indicated by e.requested_args.\u001B[39;00m\n\u001B[1;32m    380\u001B[0m     \u001B[38;5;66;03m# First, check if any of these args are already Literal-ized\u001B[39;00m\n\u001B[1;32m    381\u001B[0m     already_lit_pos \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39mrequested_args\n\u001B[1;32m    382\u001B[0m                        \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(args[i], types\u001B[38;5;241m.\u001B[39mLiteral)]\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/dispatcher.py:904\u001B[0m, in \u001B[0;36mDispatcher.compile\u001B[0;34m(self, sig)\u001B[0m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ev\u001B[38;5;241m.\u001B[39mtrigger_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumba:compile\u001B[39m\u001B[38;5;124m\"\u001B[39m, data\u001B[38;5;241m=\u001B[39mev_details):\n\u001B[1;32m    903\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 904\u001B[0m         cres \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiler\u001B[38;5;241m.\u001B[39mcompile(args, return_type)\n\u001B[1;32m    905\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mForceLiteralArg \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    906\u001B[0m         \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfolded\u001B[39m(args, kws):\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/dispatcher.py:80\u001B[0m, in \u001B[0;36m_FunctionCompiler.compile\u001B[0;34m(self, args, return_type)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompile\u001B[39m(\u001B[38;5;28mself\u001B[39m, args, return_type):\n\u001B[0;32m---> 80\u001B[0m     status, retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compile_cached(args, return_type)\n\u001B[1;32m     81\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status:\n\u001B[1;32m     82\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/dispatcher.py:94\u001B[0m, in \u001B[0;36m_FunctionCompiler._compile_cached\u001B[0;34m(self, args, return_type)\u001B[0m\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 94\u001B[0m     retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compile_core(args, return_type)\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mTypingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_failed_cache[key] \u001B[38;5;241m=\u001B[39m e\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/dispatcher.py:107\u001B[0m, in \u001B[0;36m_FunctionCompiler._compile_core\u001B[0;34m(self, args, return_type)\u001B[0m\n\u001B[1;32m    104\u001B[0m flags \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_customize_flags(flags)\n\u001B[1;32m    106\u001B[0m impl \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_implementation(args, {})\n\u001B[0;32m--> 107\u001B[0m cres \u001B[38;5;241m=\u001B[39m compiler\u001B[38;5;241m.\u001B[39mcompile_extra(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargetdescr\u001B[38;5;241m.\u001B[39mtyping_context,\n\u001B[1;32m    108\u001B[0m                               \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtargetdescr\u001B[38;5;241m.\u001B[39mtarget_context,\n\u001B[1;32m    109\u001B[0m                               impl,\n\u001B[1;32m    110\u001B[0m                               args\u001B[38;5;241m=\u001B[39margs, return_type\u001B[38;5;241m=\u001B[39mreturn_type,\n\u001B[1;32m    111\u001B[0m                               flags\u001B[38;5;241m=\u001B[39mflags, \u001B[38;5;28mlocals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlocals,\n\u001B[1;32m    112\u001B[0m                               pipeline_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpipeline_class)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# Check typing error if object mode is used\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cres\u001B[38;5;241m.\u001B[39mtyping_error \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m flags\u001B[38;5;241m.\u001B[39menable_pyobject:\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/compiler.py:739\u001B[0m, in \u001B[0;36mcompile_extra\u001B[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001B[0m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compiler entry point\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \n\u001B[1;32m    717\u001B[0m \u001B[38;5;124;03mParameter\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    735\u001B[0m \u001B[38;5;124;03m    compiler pipeline\u001B[39;00m\n\u001B[1;32m    736\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    737\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m pipeline_class(typingctx, targetctx, library,\n\u001B[1;32m    738\u001B[0m                           args, return_type, flags, \u001B[38;5;28mlocals\u001B[39m)\n\u001B[0;32m--> 739\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pipeline\u001B[38;5;241m.\u001B[39mcompile_extra(func)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/compiler.py:435\u001B[0m, in \u001B[0;36mCompilerBase.compile_extra\u001B[0;34m(self, func)\u001B[0m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompile_extra\u001B[39m(\u001B[38;5;28mself\u001B[39m, func):\n\u001B[1;32m    434\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfunc_id \u001B[38;5;241m=\u001B[39m bytecode\u001B[38;5;241m.\u001B[39mFunctionIdentity\u001B[38;5;241m.\u001B[39mfrom_function(func)\n\u001B[0;32m--> 435\u001B[0m     ExtractByteCode()\u001B[38;5;241m.\u001B[39mrun_pass(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate)\n\u001B[1;32m    437\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mlifted \u001B[38;5;241m=\u001B[39m ()\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mlifted_from \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/untyped_passes.py:64\u001B[0m, in \u001B[0;36mExtractByteCode.run_pass\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;124;03mExtract bytecode from function\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     63\u001B[0m func_id \u001B[38;5;241m=\u001B[39m state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfunc_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 64\u001B[0m bc \u001B[38;5;241m=\u001B[39m bytecode\u001B[38;5;241m.\u001B[39mByteCode(func_id)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mDUMP_BYTECODE:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28mprint\u001B[39m(bc\u001B[38;5;241m.\u001B[39mdump())\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/bytecode.py:427\u001B[0m, in \u001B[0;36mByteCodePy312.__init__\u001B[0;34m(self, func_id)\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, func_id):\n\u001B[0;32m--> 427\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(func_id)\n\u001B[1;32m    429\u001B[0m     \u001B[38;5;66;03m# initialize lazy property\u001B[39;00m\n\u001B[1;32m    430\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ordered_offsets \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/bytecode.py:396\u001B[0m, in \u001B[0;36mByteCodePy311.__init__\u001B[0;34m(self, func_id)\u001B[0m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, func_id):\n\u001B[0;32m--> 396\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(func_id)\n\u001B[1;32m    397\u001B[0m     entries \u001B[38;5;241m=\u001B[39m dis\u001B[38;5;241m.\u001B[39mBytecode(func_id\u001B[38;5;241m.\u001B[39mcode)\u001B[38;5;241m.\u001B[39mexception_entries\n\u001B[1;32m    398\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexception_entries \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfixup_eh, entries))\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/bytecode.py:294\u001B[0m, in \u001B[0;36m_ByteCode.__init__\u001B[0;34m(self, func_id)\u001B[0m\n\u001B[1;32m    291\u001B[0m labels\u001B[38;5;241m.\u001B[39madd(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    293\u001B[0m \u001B[38;5;66;03m# A map of {offset: ByteCodeInst}\u001B[39;00m\n\u001B[0;32m--> 294\u001B[0m table \u001B[38;5;241m=\u001B[39m OrderedDict(ByteCodeIter(code))\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_lineno(table, code)\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc_id \u001B[38;5;241m=\u001B[39m func_id\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/numba/core/bytecode.py:266\u001B[0m, in \u001B[0;36mByteCodeIter.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    265\u001B[0m     offset, opcode, arg, nextoffset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fetch_opcode()\n\u001B[0;32m--> 266\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m offset, ByteCodeInst(offset\u001B[38;5;241m=\u001B[39moffset, opcode\u001B[38;5;241m=\u001B[39mopcode, arg\u001B[38;5;241m=\u001B[39marg,\n\u001B[1;32m    267\u001B[0m                                 nextoffset\u001B[38;5;241m=\u001B[39mnextoffset)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "generate_explanations(rules_data_L, db_L_dir, datasets_path_L)",
   "id": "3eb943b8bff1fb77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T22:25:05.676061Z",
     "start_time": "2025-11-09T22:24:20.023136Z"
    }
   },
   "cell_type": "code",
   "source": "generate_explanations(rules_data_M, db_M_dir, datasets_path_M)",
   "id": "50fbe67227dcc32b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med1_find_pattern_rot_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 26%|██▌       | 13/50 [00:00<00:00, 121.59it/s]\u001B[A\n",
      " 52%|█████▏    | 26/50 [00:00<00:00, 109.40it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 116.02it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing shap values\n",
      "Generating shap images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 40%|████      | 20/50 [00:00<00:00, 39.76it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.67it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med1_find_pattern_rot_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 42%|████▏     | 21/50 [00:00<00:00, 203.61it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 185.38it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      " 25%|██▌       | 1/4 [00:16<00:50, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med2_yellow_square_even_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 44%|████▍     | 22/50 [00:00<00:00, 211.09it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 207.46it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing shap values\n",
      "Generating shap images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:01<00:00, 32.03it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med2_yellow_square_even_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 28%|██▊       | 14/50 [00:00<00:00, 130.42it/s]\u001B[A\n",
      " 56%|█████▌    | 28/50 [00:00<00:00, 127.17it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 151.09it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      " 50%|█████     | 2/4 [00:26<00:25, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med3_find_pattern_rot_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 44%|████▍     | 22/50 [00:00<00:00, 215.74it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 155.46it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing shap values\n",
      "Generating shap images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:01<00:00, 31.33it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med3_find_pattern_rot_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 42%|████▏     | 21/50 [00:00<00:00, 204.12it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 193.14it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      " 75%|███████▌  | 3/4 [00:36<00:11, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med4_blue_triangle_even_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 26%|██▌       | 13/50 [00:00<00:00, 128.97it/s]\u001B[A\n",
      " 54%|█████▍    | 27/50 [00:00<00:00, 129.76it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 127.12it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing shap values\n",
      "Generating shap images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:01<00:00, 32.10it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset content for med4_blue_triangle_even_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A\n",
      " 44%|████▍     | 22/50 [00:00<00:00, 213.94it/s]\u001B[A\n",
      "100%|██████████| 50/50 [00:00<00:00, 200.70it/s]\u001B[A\n",
      "Using cache found in /home/jleguy/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 4/4 [00:45<00:00, 11.41s/it]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# from transformers import AutoModelForCausalLM\n",
    "# import csv\n",
    "# from xaipatimg.ml.xai import generate_LLM_explanations, create_xai_index\n",
    "# from tqdm import tqdm\n",
    "#\n",
    "# model_id = \"openai/gpt-oss-20b\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=\"auto\",\n",
    "# )\n",
    "#\n",
    "# for rule_idx in tqdm(range(len(rules_data))):\n",
    "#\n",
    "#     model_dir = os.path.join(model_dir_root, rules_data[rule_idx][\"name\"])\n",
    "#     dataset_filename = rules_data[rule_idx][\"name\"] + \"_test.csv\"\n",
    "#\n",
    "#     # Extracting the subset of indices of samples selected for the experimental interface, in order to ease the cost of calculation\n",
    "#     interface_content_path = os.path.join(interface_dir, \"res\", \"tasks\", f\"{rules_data[rule_idx][\"name\"]}_content.csv\")\n",
    "#     interface_selected_idx = [int(row[\"og_idx\"]) for row in list(csv.DictReader(open(interface_content_path), delimiter=','))]\n",
    "#\n",
    "#     xai_output_paths = {\n",
    "#         \"shap\" : \"shap\",\n",
    "#         \"cf\" : \"cf\",\n",
    "#         \"llm\" : \"llm\",\n",
    "#     }\n",
    "#     generate_LLM_explanations(db_dir, db, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "#                               model_dir=model_dir, llm_model=llm_model, llm_tokenizer=tokenizer,\n",
    "#                               xai_output_path=os.path.join(model_dir, xai_output_paths[\"llm\"]),\n",
    "#                               explicit_colors_dict=explict_colors_dict, question=rules_data[rule_idx][\"question\"],\n",
    "#                               yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path,\n",
    "#                               yes_pred_img_path_small=yes_small_pred_img_path, no_pred_img_path_small=no_small_pred_img_path,\n",
    "#                               device=\"cuda:0\", dataset_size=XAI_DATASET_SIZE, only_for_index=interface_selected_idx,\n",
    "#                               path_to_counterfactuals_dir_for_model_errors=os.path.join(model_dir, xai_output_paths[\"cf\"]),\n",
    "#                               pos_llm_scaffold=rules_data[rule_idx][\"pos_llm_scaffold\"], neg_llm_scaffold=rules_data[rule_idx][\"neg_llm_scaffold\"])\n",
    "#\n",
    "#     create_xai_index(db_dir, dataset_filename=dataset_filename, model_dir=model_dir, xai_dirs=xai_output_paths, dataset_size=XAI_DATASET_SIZE, device=\"cuda:0\")\n"
   ],
   "id": "c418ac7342c2bf59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3d72dcaaf6eae03d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1f2b46b2badd40d5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
