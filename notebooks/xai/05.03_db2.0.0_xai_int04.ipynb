{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:45:34.265079Z",
     "start_time": "2025-11-18T09:45:34.262275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "db_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db2.0.0/\"\n",
    "datasets_dir_path = os.environ[\"DATA\"] + \"PatImgXAI_data/db2.0.0/datasets/03_protov4/\"\n",
    "model_dir_root = os.environ[\"DATA\"] + \"models/db2.0.0/03_protov4/\"\n",
    "\n",
    "shap_scale_img_path = os.path.join(db_dir,\"shap_scale.png\")\n",
    "yes_pred_img_path = os.path.join(db_dir,\"button_yes.png\")\n",
    "no_pred_img_path = os.path.join(db_dir,\"button_no.png\")\n",
    "yes_small_pred_img_path = os.path.join(db_dir,\"button_yes_small.png\")\n",
    "no_small_pred_img_path = os.path.join(db_dir,\"button_no_small.png\")\n",
    "pos_pred_legend_path = os.path.join(db_dir,\"cf_info_pos.png\")\n",
    "neg_pred_legend_path = os.path.join(db_dir,\"cf_info_neg.png\")\n",
    "interface_dir = os.environ[\"DATA\"] + \"webinterfaces/int04_prototype/\"\n",
    "\n",
    "XAI_DATASET_SIZE = 100\n",
    "\n",
    "N_JOBS = 20\n",
    "N_JOBS_GPU = 1"
   ],
   "id": "acb2ace512421a34",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:45:34.308428Z",
     "start_time": "2025-11-18T09:45:34.305489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of images generated\n",
    "NBGEN = 1000000\n",
    "\n",
    "# Grid division of each image\n",
    "X_DIVISIONS = 6\n",
    "Y_DIVISIONS = 6\n",
    "\n",
    "# Size of the images in pixels\n",
    "img_size = (700, 700)\n",
    "\n",
    "# Probability to generate a geometrical shape at each position in the grid\n",
    "SHAPE_PROB = 0.5\n",
    "\n",
    "# Define available shapes\n",
    "SHAPES = ['circle', 'square', 'triangle']\n",
    "COLORS  = [\"#A33E9A\", \"#E0B000\", \"#0C90C0\"]\n",
    "\n",
    "explict_colors_dict = {\n",
    "    \"#A33E9A\": \"purple\",\n",
    "    \"#E0B000\": \"yellow\",\n",
    "    \"#0C90C0\": \"blue\"\n",
    "}"
   ],
   "id": "5b67393fc1a2c479",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:45:35.041280Z",
     "start_time": "2025-11-18T09:45:34.382612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_exist_row_with_only_shape, generic_rule_N_times_color_exactly, \\\n",
    "    generic_rule_shape_color_plus_shape_equals_N, generic_rule_shape_in_every_row, generic_rule_shape_color_times_2_shape_equals_shape\n",
    "\n",
    "rules_data = [\n",
    "    {\"name\": \"disc_1_triangle_all\", \"gen_fun\": generic_rule_shape_in_every_row, \"gen_kwargs\": {\"shape\": \"triangle\", \"y_division\": Y_DIVISIONS}, \"question\": \"In the image, is there a triangle in every row (1, ..., 6)?\", \"target_acc\" : 1.0, \"shown_acc\" : 1.0, \"samples_interface\": 3, \"pos_llm_scaffold\": \"The AI predicts |YES| because every row contains at least one triangle : \\n - Row 1 : XX, XX, XX\\n- Row 2 : XX, XX, XX\\n- Row 3 : XX, XX, XX\\n- Row 4 : XX, XX, XX\\n- Row 5 : XX, XX, XX\\n- Row 5 : XX, XX, XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because the rows X and X do not contain any triangle.\"},\n",
    "\n",
    "    {\"name\": \"disc_1_triangle_all_2\", \"gen_fun\": generic_rule_shape_in_every_row, \"gen_kwargs\": {\"shape\": \"triangle\", \"y_division\": Y_DIVISIONS}, \"question\": \"In the image, is there a triangle in every row (1, ..., 6)?\", \"target_acc\" : 1.0, \"shown_acc\" : 1.0, \"samples_interface\": 5, \"pos_llm_scaffold\": \"The AI predicts |YES| because every row contains at least one triangle : \\n - Row 1 : XX, XX, XX\\n- Row 2 : XX, XX, XX\\n- Row 3 : XX, XX, XX\\n- Row 4 : XX, XX, XX\\n- Row 5 : XX, XX, XX\\n- Row 5 : XX, XX, XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because the rows X and X do not contain any triangle.\"},\n",
    "\n",
    "    {\"name\": \"disc_1_triangle_all_3\", \"gen_fun\": generic_rule_shape_in_every_row, \"gen_kwargs\": {\"shape\": \"triangle\", \"y_division\": Y_DIVISIONS}, \"question\": \"In the image, is there a triangle in every row (1, ..., 6)?\", \"target_acc\" : 1.0, \"shown_acc\" : 1.0, \"samples_interface\": 5, \"pos_llm_scaffold\": \"The AI predicts |YES| because every row contains at least one triangle : \\n - Row 1 : XX, XX, XX\\n- Row 2 : XX, XX, XX\\n- Row 3 : XX, XX, XX\\n- Row 4 : XX, XX, XX\\n- Row 5 : XX, XX, XX\\n- Row 5 : XX, XX, XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because the rows X and X do not contain any triangle.\"},\n",
    "\n",
    "\n",
    "    {\"name\": \"easy_1_6_blue\", \"gen_fun\": generic_rule_N_times_color_exactly, \"gen_kwargs\": {\"color\": \"#0C90C0\", \"N\": 6, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}, \"question\": \"In the image, are there exactly 6 blue symbols?\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 7, \"pos_llm_scaffold\": \"The AI predicts |YES| because there is exactly 6 blue symbols, which are located at :\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because there is X blue symbols instead of 6. They are located at : \\n- XX\\n- XX\\n- XX\\n- XX\\n- XX.\"},\n",
    "\n",
    "    {\"name\": \"easy_3_7_purple\", \"gen_fun\": generic_rule_N_times_color_exactly, \"gen_kwargs\": {\"color\": \"#A33E9A\", \"N\": 7, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}, \"question\": \"In the image, are there exactly 7 purple symbols?\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14, \"pos_llm_scaffold\": \"The AI predicts |YES| because there is exactly 7 purple symbols, which are located at :\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because there is X purple symbols instead of 7. They are located at : \\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX.\"},\n",
    "\n",
    "    {\"name\": \"easy_4_row_triangle\", \"gen_fun\": generic_rule_exist_row_with_only_shape, \"gen_kwargs\": {\"shape\": \"triangle\", \"y_division\": Y_DIVISIONS},\n",
    "     \"question\": \"In the image, is there at least one row (1, ..., 6) containing only triangles?\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14, \"pos_llm_scaffold\": \"The AI predicts |YES| because there is at least one row which contains only triangles : \\nRow X contains only triangles which are located at XX, XX, XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because there is not a single row containing only triangles :\\nRow 1 contains a non-triangle symbol at XX\\nRow 2 contains non-triangle symbols at XX, XX, XX.\\nRow 3 does not contain any symbol at all\\n ...\"},\n",
    "\n",
    "    {\"name\": \"easy_5_5_yellow\", \"gen_fun\": generic_rule_N_times_color_exactly, \"gen_kwargs\": {\"color\": \"#E0B000\", \"N\": 5, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS}, \"question\": \"In the image, are there exactly 5 yellow symbols?\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14,  \"pos_llm_scaffold\": \"The AI predicts |YES| because there is exactly 5 yellow symbols, which are located at :\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because there is X yellow symbols instead of 5, which are located at : \\n- XX\\n- XX\\n- XX\\n- XX\\n- XX\\n- XX.\"},\n",
    "\n",
    "    {\"name\": \"easy_6_row_square\", \"gen_fun\": generic_rule_exist_row_with_only_shape, \"gen_kwargs\": {\"shape\": \"square\", \"y_division\": Y_DIVISIONS},\n",
    "     \"question\": \"In the image, is there at least one row (1, ..., 6) containing only squares?\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14, \"pos_llm_scaffold\": \"The AI predicts |YES| because there is at least one row which contains only squares : \\nRow X contains only squares which are located at XX, XX, XX\", \"neg_llm_scaffold\": \"The AI predicts |NO| because there is not a single row containing only squares :\\nRow 1 contains a non-square symbol at XX\\nRow 2 contains non-square symbols at XX, XX, XX.\\nRow 3 does not contain any symbol at all\\n ...\"},\n",
    "\n",
    "\n",
    "    {\"name\": \"hard_1_blue_square_plus_circle_8\", \"gen_fun\": generic_rule_shape_color_plus_shape_equals_N, \"gen_kwargs\": {\"color1\": \"#0C90C0\", \"shape1\": \"square\", \"shape2\": \"circle\", \"N\": 8, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS,},\n",
    "     \"question\": \"In the image, does the number of blue squares plus (+) the number of circles equal to 8?\", \"question_llm\": \"In the image, does the number of blue squares plus (+) the number of circles of any color equal to 8\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 7, \"pos_llm_scaffold\": \"The AI predicts |YES| because \\n\\n There is a total of X blue squares at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n\\n X + X = 8\", \"neg_llm_scaffold\": \"The AI predicts |NO| because \\n\\n There is a total of X blue squares at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n X + X = X ≠ 8\"},\n",
    "\n",
    "    {\"name\": \"hard_3_yellow_circle_plus_triangle_9\", \"gen_fun\": generic_rule_shape_color_plus_shape_equals_N, \"gen_kwargs\": {\"color1\": \"#E0B000\", \"shape1\": \"circle\", \"shape2\": \"triangle\", \"N\": 9, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS},\n",
    "     \"question\": \"In the image, does the number of yellow circles plus (+) the number of triangles equal to 9?\",\n",
    "     \"question_llm\": \"In the image, does the number of yellow circles plus (+) the number of triangles of any color equal to 9?\",\"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14, \"pos_llm_scaffold\": \"The AI predicts |YES| because \\n\\n There is a total of X yellow circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X triangles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n\\n X + X = 9\", \"neg_llm_scaffold\": \"The AI predicts |NO| because \\n\\n There is a total of X yellow circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X triangles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n X + X = X ≠ 9\"},\n",
    "    #\n",
    "    {\"name\": \"hard_4_purple_squares_times2_circles\", \"gen_fun\": generic_rule_shape_color_times_2_shape_equals_shape, \"gen_kwargs\": {\"color1\": \"#A33E9A\", \"shape1\": \"square\", \"shape2\": \"circle\", \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS,},\n",
    "     \"question\": \"In the image, does the number of purple squares multiplied by 2 (×2) equal to the number of circles?\",\n",
    "     \"question_llm\": \"In the image, does the number of purple squares multiplied by 2 (×2) equal to the number of circles of any color?\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14, \"pos_llm_scaffold\": \"The AI predicts |YES| because \\n\\n There is a total of X purple squares at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n\\n X × 2 = X\", \"neg_llm_scaffold\": \"There is a total of X purple squares at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n\\n X × 2 = X ≠ X\"},\n",
    "\n",
    "    {\"name\": \"hard_5_purple_triangle_plus_square_7\", \"gen_fun\": generic_rule_shape_color_plus_shape_equals_N, \"gen_kwargs\": {\"color1\": \"#A33E9A\", \"shape1\": \"triangle\", \"shape2\": \"square\", \"N\": 7, \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS},\n",
    "     \"question\": \"In the image, does the number of purple triangles plus (+) the number of squares equal to 7?\",\n",
    "     \"question_llm\": \"In the image, does the number of purple triangles plus (+) the number of squares of any color equal to 7?\", \"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14, \"pos_llm_scaffold\": \"The AI predicts |YES| because \\n\\n There is a total of X purple triangles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X squares at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n\\n X + X = 7\", \"neg_llm_scaffold\": \"The AI predicts |NO| because \\n\\n There is a total of X purple triangles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X squares at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n X + X = X ≠ 7\"},\n",
    "\n",
    "    {\"name\": \"hard_6_blue_circles_times2_triangles\", \"gen_fun\": generic_rule_shape_color_times_2_shape_equals_shape, \"gen_kwargs\": {\"color1\": \"#0C90C0\", \"shape1\": \"circle\", \"shape2\": \"triangle\", \"x_division\": X_DIVISIONS, \"y_division\": Y_DIVISIONS,},\n",
    "     \"question\": \"In the image, does the number of blue circles multiplied by 2 (×2) equal to the number of triangles?\", \"question_llm\": \"In the image, does the number of blue circles multiplied by 2 (×2) equal to the number of triangles of any color?\",\"target_acc\": 0.9, \"shown_acc\": 0.85, \"samples_interface\": 14, \"pos_llm_scaffold\": \"The AI predicts |YES| because \\n\\n There is a total of X blue circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X triangles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n\\n X × 2 = X\", \"neg_llm_scaffold\": \"There is a total of X blue circles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n \\nThere is a total of X triangles at positions : \\n- XX\\n- XX\\n- XX\\n- XX\\n\\n X × 2 = X ≠ X\"},\n",
    "]\n"
   ],
   "id": "c17bf53f3134ebce",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:45:50.671941Z",
     "start_time": "2025-11-18T09:45:35.045113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.dbimg import load_db\n",
    "\n",
    "db = load_db(db_dir)"
   ],
   "id": "fb0bcd9d369ef2ef",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:46:03.868675Z",
     "start_time": "2025-11-18T09:45:50.704356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.ml.xai import generate_shap_resnet, generate_counterfactuals_resnet_random_approach, \\\n",
    "    create_xai_index, generate_cam_resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "for rule_idx in tqdm(range(len(rules_data))):\n",
    "\n",
    "    model_dir = os.path.join(model_dir_root, rules_data[rule_idx][\"name\"])\n",
    "    dataset_filename = rules_data[rule_idx][\"name\"] + \"_test.csv\"\n",
    "    generic_rule_fun = rules_data[rule_idx][\"gen_fun\"]\n",
    "    generic_rule_fun_kwargs = rules_data[rule_idx][\"gen_kwargs\"]\n",
    "    xai_output_paths = {\n",
    "        \"shap\" : \"shap\",\n",
    "        \"cf\" : \"cf\"\n",
    "    }\n",
    "\n",
    "    # generate_shap_resnet(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "    #                        model_dir=model_dir, xai_output_path=os.path.join(model_dir, xai_output_paths[\"shap\"]),\n",
    "    #                        yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path, device=\"cuda:0\", n_jobs=N_JOBS,\n",
    "    #                        dataset_size=XAI_DATASET_SIZE, masker=\"ndarray\", shap_scale_img_path=shap_scale_img_path)\n",
    "    #\n",
    "    # generate_counterfactuals_resnet18_random_approach(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "    #                                                   model_dir=model_dir,\n",
    "    #                                                   xai_output_path=os.path.join(model_dir, xai_output_paths[\"cf\"]),\n",
    "    #                                                   yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path,\n",
    "    #                                                   shapes=SHAPES, colors=COLORS, empty_probability=1-SHAPE_PROB,\n",
    "    #                                                   max_depth=10, nb_tries_per_depth=2000, generic_rule_fun=generic_rule_fun,\n",
    "    #                                                   devices=[\"cuda:0\", \"cuda:1\"], n_jobs=N_JOBS_GPU,\n",
    "    #                                                   dataset_size=XAI_DATASET_SIZE,pos_pred_legend_path=pos_pred_legend_path,\n",
    "    #                                                   neg_pred_legend_path=neg_pred_legend_path,\n",
    "    #                                                   **generic_rule_fun_kwargs)\n",
    "    #\n",
    "    # create_xai_index(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename, model_dir=model_dir,\n",
    "    #                  xai_dirs=xai_output_paths, dataset_size=XAI_DATASET_SIZE, device=\"cuda:0\")\n"
   ],
   "id": "381e2ac75e35913f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jleguy/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 13/13 [00:00<00:00, 272629.76it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T09:46:06.286180Z",
     "start_time": "2025-11-18T09:46:03.902047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import csv\n",
    "from xaipatimg.ml.xai import generate_LLM_explanations, create_xai_index\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_id = \"openai/gpt-oss-20b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "\n",
    "for rule_idx in tqdm(range(len(rules_data))):\n",
    "\n",
    "    model_dir = os.path.join(model_dir_root, rules_data[rule_idx][\"name\"])\n",
    "    dataset_filename = rules_data[rule_idx][\"name\"] + \"_test.csv\"\n",
    "\n",
    "    # Extracting the subset of indices of samples selected for the experimental interface, in order to ease the cost of calculation\n",
    "    interface_content_path = os.path.join(interface_dir, \"res\", \"tasks\", f\"{rules_data[rule_idx][\"name\"]}_content.csv\")\n",
    "    interface_selected_idx = [int(row[\"og_idx\"]) for row in list(csv.DictReader(open(interface_content_path), delimiter=','))]\n",
    "\n",
    "    xai_output_paths = {\n",
    "        \"shap\" : \"shap\",\n",
    "        \"cf\" : \"cf\",\n",
    "        \"llm\" : \"llm\",\n",
    "    }\n",
    "    generate_LLM_explanations(db_dir, db, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "                              model_dir=model_dir, llm_model=llm_model, llm_tokenizer=tokenizer,\n",
    "                              xai_output_path=os.path.join(model_dir, xai_output_paths[\"llm\"]),\n",
    "                              explicit_colors_dict=explict_colors_dict, question=rules_data[rule_idx][\"question\"],\n",
    "                              yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path,\n",
    "                              yes_pred_img_path_small=yes_small_pred_img_path, no_pred_img_path_small=no_small_pred_img_path,\n",
    "                              device=\"cuda:0\", dataset_size=XAI_DATASET_SIZE, only_for_index=interface_selected_idx,\n",
    "                              path_to_counterfactuals_dir_for_model_errors=os.path.join(model_dir, xai_output_paths[\"cf\"]),\n",
    "                              pos_llm_scaffold=rules_data[rule_idx][\"pos_llm_scaffold\"],\n",
    "                              neg_llm_scaffold=rules_data[rule_idx][\"neg_llm_scaffold\"])\n",
    "\n",
    "    create_xai_index(db_dir, datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename, model_dir=model_dir,\n",
    "                     xai_dirs=xai_output_paths,\n",
    "                     dataset_size=XAI_DATASET_SIZE,device=\"cuda:0\")\n"
   ],
   "id": "c418ac7342c2bf59",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "MXFP4 quantization requires Triton and kernels installed: CUDA requires Triton >= 3.4.0, XPU requires Triton >= 3.5.0, we will default to dequantizing the model to bf16\n",
      "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 7.69 GiB of which 438.31 MiB is free. Including non-PyTorch memory, this process has 7.25 GiB memory in use. Of the allocated memory 5.55 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m model_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai/gpt-oss-20b\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      8\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_id)\n\u001B[0;32m----> 9\u001B[0m llm_model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m     10\u001B[0m     model_id,\n\u001B[1;32m     11\u001B[0m     device_map\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m     torch_dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m rule_idx \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(rules_data))):\n\u001B[1;32m     17\u001B[0m     model_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_dir_root, rules_data[rule_idx][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:604\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    602\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mconfig_class \u001B[38;5;241m==\u001B[39m config\u001B[38;5;241m.\u001B[39msub_configs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext_config\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    603\u001B[0m         config \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mget_text_config()\n\u001B[0;32m--> 604\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m    605\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    606\u001B[0m     )\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    609\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    610\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/modeling_utils.py:277\u001B[0m, in \u001B[0;36mrestore_default_dtype.<locals>._wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m old_dtype \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mget_default_dtype()\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    279\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_default_dtype(old_dtype)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/modeling_utils.py:5048\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   5038\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dtype_orig \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5039\u001B[0m         torch\u001B[38;5;241m.\u001B[39mset_default_dtype(dtype_orig)\n\u001B[1;32m   5041\u001B[0m     (\n\u001B[1;32m   5042\u001B[0m         model,\n\u001B[1;32m   5043\u001B[0m         missing_keys,\n\u001B[1;32m   5044\u001B[0m         unexpected_keys,\n\u001B[1;32m   5045\u001B[0m         mismatched_keys,\n\u001B[1;32m   5046\u001B[0m         offload_index,\n\u001B[1;32m   5047\u001B[0m         error_msgs,\n\u001B[0;32m-> 5048\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_load_pretrained_model(\n\u001B[1;32m   5049\u001B[0m         model,\n\u001B[1;32m   5050\u001B[0m         state_dict,\n\u001B[1;32m   5051\u001B[0m         checkpoint_files,\n\u001B[1;32m   5052\u001B[0m         pretrained_model_name_or_path,\n\u001B[1;32m   5053\u001B[0m         ignore_mismatched_sizes\u001B[38;5;241m=\u001B[39mignore_mismatched_sizes,\n\u001B[1;32m   5054\u001B[0m         sharded_metadata\u001B[38;5;241m=\u001B[39msharded_metadata,\n\u001B[1;32m   5055\u001B[0m         device_map\u001B[38;5;241m=\u001B[39mdevice_map,\n\u001B[1;32m   5056\u001B[0m         disk_offload_folder\u001B[38;5;241m=\u001B[39moffload_folder,\n\u001B[1;32m   5057\u001B[0m         dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   5058\u001B[0m         hf_quantizer\u001B[38;5;241m=\u001B[39mhf_quantizer,\n\u001B[1;32m   5059\u001B[0m         keep_in_fp32_regex\u001B[38;5;241m=\u001B[39mkeep_in_fp32_regex,\n\u001B[1;32m   5060\u001B[0m         device_mesh\u001B[38;5;241m=\u001B[39mdevice_mesh,\n\u001B[1;32m   5061\u001B[0m         key_mapping\u001B[38;5;241m=\u001B[39mkey_mapping,\n\u001B[1;32m   5062\u001B[0m         weights_only\u001B[38;5;241m=\u001B[39mweights_only,\n\u001B[1;32m   5063\u001B[0m     )\n\u001B[1;32m   5064\u001B[0m \u001B[38;5;66;03m# make sure token embedding weights are still tied if needed\u001B[39;00m\n\u001B[1;32m   5065\u001B[0m model\u001B[38;5;241m.\u001B[39mtie_weights()\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/modeling_utils.py:5468\u001B[0m, in \u001B[0;36mPreTrainedModel._load_pretrained_model\u001B[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001B[0m\n\u001B[1;32m   5465\u001B[0m         args_list \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mtqdm(args_list, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading checkpoint shards\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   5467\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m args \u001B[38;5;129;01min\u001B[39;00m args_list:\n\u001B[0;32m-> 5468\u001B[0m         _error_msgs, disk_offload_index \u001B[38;5;241m=\u001B[39m load_shard_file(args)\n\u001B[1;32m   5469\u001B[0m         error_msgs \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m _error_msgs\n\u001B[1;32m   5471\u001B[0m \u001B[38;5;66;03m# Save offloaded index if needed\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/modeling_utils.py:843\u001B[0m, in \u001B[0;36mload_shard_file\u001B[0;34m(args)\u001B[0m\n\u001B[1;32m    841\u001B[0m \u001B[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001B[39;00m\n\u001B[1;32m    842\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_fsdp_enabled() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_local_dist_rank_0() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_quantized):\n\u001B[0;32m--> 843\u001B[0m     disk_offload_index \u001B[38;5;241m=\u001B[39m _load_state_dict_into_meta_model(\n\u001B[1;32m    844\u001B[0m         model,\n\u001B[1;32m    845\u001B[0m         state_dict,\n\u001B[1;32m    846\u001B[0m         shard_file,\n\u001B[1;32m    847\u001B[0m         reverse_key_renaming_mapping,\n\u001B[1;32m    848\u001B[0m         device_map\u001B[38;5;241m=\u001B[39mdevice_map,\n\u001B[1;32m    849\u001B[0m         disk_offload_folder\u001B[38;5;241m=\u001B[39mdisk_offload_folder,\n\u001B[1;32m    850\u001B[0m         disk_offload_index\u001B[38;5;241m=\u001B[39mdisk_offload_index,\n\u001B[1;32m    851\u001B[0m         hf_quantizer\u001B[38;5;241m=\u001B[39mhf_quantizer,\n\u001B[1;32m    852\u001B[0m         keep_in_fp32_regex\u001B[38;5;241m=\u001B[39mkeep_in_fp32_regex,\n\u001B[1;32m    853\u001B[0m         device_mesh\u001B[38;5;241m=\u001B[39mdevice_mesh,\n\u001B[1;32m    854\u001B[0m     )\n\u001B[1;32m    856\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m error_msgs, disk_offload_index\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/modeling_utils.py:774\u001B[0m, in \u001B[0;36m_load_state_dict_into_meta_model\u001B[0;34m(model, state_dict, shard_file, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, hf_quantizer, keep_in_fp32_regex, device_mesh)\u001B[0m\n\u001B[1;32m    770\u001B[0m     _load_parameter_into_model(model, param_name, param\u001B[38;5;241m.\u001B[39mto(param_device))\n\u001B[1;32m    772\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    773\u001B[0m     \u001B[38;5;66;03m# TODO naming is stupid it loads it as well\u001B[39;00m\n\u001B[0;32m--> 774\u001B[0m     hf_quantizer\u001B[38;5;241m.\u001B[39mcreate_quantized_param(model, param, param_name, param_device)\n\u001B[1;32m    776\u001B[0m     \u001B[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001B[39;00m\n\u001B[1;32m    777\u001B[0m     \u001B[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001B[39;00m\n\u001B[1;32m    778\u001B[0m     \u001B[38;5;66;03m# in comparison to the sharded model across GPUs.\u001B[39;00m\n\u001B[1;32m    779\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_fsdp_enabled() \u001B[38;5;129;01mor\u001B[39;00m is_deepspeed_zero3_enabled():\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/quantizers/quantizer_mxfp4.py:246\u001B[0m, in \u001B[0;36mMxfp4HfQuantizer.create_quantized_param\u001B[0;34m(self, model, param_value, param_name, target_device, **kwargs)\u001B[0m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquantization_config\u001B[38;5;241m.\u001B[39mdequantize:\n\u001B[1;32m    243\u001B[0m     \u001B[38;5;66;03m# dq_param_name is the name of the parameter without the blocks or scales suffix, it's used in this case since we don't switch linears\u001B[39;00m\n\u001B[1;32m    244\u001B[0m     \u001B[38;5;66;03m# so we only have the original param name\u001B[39;00m\n\u001B[1;32m    245\u001B[0m     dq_param_name \u001B[38;5;241m=\u001B[39m param_name[: \u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_blocks\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[0;32m--> 246\u001B[0m     dequantize(module, param_name, param_value, target_device, dq_param_name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mshard_kwargs)\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    248\u001B[0m     load_and_swizzle_mxfp4(\n\u001B[1;32m    249\u001B[0m         module,\n\u001B[1;32m    250\u001B[0m         param_name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mshard_kwargs,\n\u001B[1;32m    255\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:351\u001B[0m, in \u001B[0;36mdequantize\u001B[0;34m(module, param_name, param_value, target_device, dq_param_name, **kwargs)\u001B[0m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;28msetattr\u001B[39m(module, param_name\u001B[38;5;241m.\u001B[39mrsplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m1\u001B[39m], param_value)\n\u001B[1;32m    350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(module, blocks_attr) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(module, scales_attr):\n\u001B[0;32m--> 351\u001B[0m     dequantized \u001B[38;5;241m=\u001B[39m convert_moe_packed_tensors(\u001B[38;5;28mgetattr\u001B[39m(module, blocks_attr), \u001B[38;5;28mgetattr\u001B[39m(module, scales_attr))\n\u001B[1;32m    352\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m target_device \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m    353\u001B[0m         torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n",
      "File \u001B[0;32m~/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/transformers/integrations/mxfp4.py:140\u001B[0m, in \u001B[0;36mconvert_moe_packed_tensors\u001B[0;34m(blocks, scales, dtype, rows_per_chunk)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;66;03m# nibble indices -> int64\u001B[39;00m\n\u001B[1;32m    139\u001B[0m idx_lo \u001B[38;5;241m=\u001B[39m (blk \u001B[38;5;241m&\u001B[39m \u001B[38;5;241m0x0F\u001B[39m)\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m--> 140\u001B[0m idx_hi \u001B[38;5;241m=\u001B[39m (blk \u001B[38;5;241m>>\u001B[39m \u001B[38;5;241m4\u001B[39m)\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[1;32m    142\u001B[0m sub \u001B[38;5;241m=\u001B[39m out[r0:r1]\n\u001B[1;32m    143\u001B[0m sub[:, \u001B[38;5;241m0\u001B[39m::\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m lut[idx_lo]\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 7.69 GiB of which 438.31 MiB is free. Including non-PyTorch memory, this process has 7.25 GiB memory in use. Of the allocated memory 5.55 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3d72dcaaf6eae03d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1f2b46b2badd40d5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
