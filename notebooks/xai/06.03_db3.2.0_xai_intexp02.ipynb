{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:30.822300Z",
     "start_time": "2026-01-15T14:04:30.817816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "db_S_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0/S/\"\n",
    "db_L_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0/L/\"\n",
    "db_M_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0/M/\"\n",
    "db_XS_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0/XS/\"\n",
    "db_patterns_dir = os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0/patterns/\"\n",
    "\n",
    "model_dir_root = os.environ[\"DATA\"] + \"models/db3.2.0/01_expv1/\"\n",
    "shap_scale_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0\", \"shap_scale.png\")\n",
    "yes_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0\", \"button_yes.png\")\n",
    "no_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0\", \"button_no.png\")\n",
    "yes_small_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0\", \"button_yes_small.png\")\n",
    "no_small_pred_img_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0\", \"button_no_small.png\")\n",
    "pos_pred_legend_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0\", \"cf_info_pos.png\")\n",
    "neg_pred_legend_path = os.path.join(os.environ[\"DATA\"] + \"PatImgXAI_data/db3.2.0\", \"cf_info_neg.png\")\n",
    "interface_dir = os.environ[\"DATA\"] + \"webinterfaces/exp02/\"\n",
    "\n",
    "XAI_DATASET_SIZE = 200\n",
    "# XAI_DATASET_SIZE = 20\n",
    "\n",
    "N_JOBS = 20\n",
    "N_JOBS_GPU = 4\n",
    "\n",
    "RESNET_TYPE = \"resnet18\""
   ],
   "id": "367bbf75adb522e1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:30.864070Z",
     "start_time": "2026-01-15T14:04:30.861590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of images generated\n",
    "NBGEN_full_per_size = 5000000\n",
    "NBGEN_patterns = 1000\n",
    "\n",
    "# Grid division for full image\n",
    "X_DIVISIONS_L = 15\n",
    "Y_DIVISIONS_L = 15\n",
    "X_DIVISIONS_S = 9\n",
    "Y_DIVISIONS_S = 9\n",
    "X_DIVISIONS_M = 12\n",
    "Y_DIVISIONS_M = 12\n",
    "X_DIVISIONS_XS = 5\n",
    "Y_DIVISIONS_XS = 5\n",
    "\n",
    "# Grid division of patterns\n",
    "X_DIVISIONS_PATTERNS = 2\n",
    "Y_DIVISIONS_PATTERNS = 2\n",
    "\n",
    "# Size of the images in pixels\n",
    "img_size = (700, 700)\n",
    "img_size_patterns = (300, 300)\n",
    "\n",
    "# Probability to generate a geometrical shape at each position in the grid\n",
    "SHAPE_PROB = 0.5\n",
    "\n",
    "# Define available shapes\n",
    "SHAPES = ['c', 's', 't']\n",
    "COLORS  = [\"p\", \"y\", \"b\"]"
   ],
   "id": "fb72e19e3a230f15",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:31.291948Z",
     "start_time": "2026-01-15T14:04:30.957132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.dbimg import load_db\n",
    "\n",
    "db_patterns = load_db(db_patterns_dir)"
   ],
   "id": "e1ffb9995502154e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:31.311367Z",
     "start_time": "2026-01-15T14:04:31.303464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "pattern_3sym_2col_keys = []\n",
    "\n",
    "# Extracting list of patterns that contain 3 symbols of 3 different shapes and 2 different colors. The two items of the same color cannot be\n",
    "# on a diagonal.\n",
    "for k, v in db_patterns.items():\n",
    "    if len(v[\"cnt\"]) == 3:\n",
    "        img_col_d = {}\n",
    "        img_shape_d = {}\n",
    "        color_matrix = np.full((2, 2), \"\", dtype=\"U100\")\n",
    "        for entry in v[\"cnt\"]:\n",
    "            img_col_d[entry[\"col\"]] = True\n",
    "            img_shape_d[entry[\"shp\"]] = True\n",
    "            color_matrix[entry[\"pos\"][0]][entry[\"pos\"][1]] = entry[\"col\"]\n",
    "\n",
    "        same_color_on_diagonal = color_matrix[0][0] == color_matrix[1][1] or color_matrix[0][1] == color_matrix[1][0]\n",
    "\n",
    "        if len(img_col_d.keys()) == 2 and len(img_shape_d.keys()) == 3 and not same_color_on_diagonal:\n",
    "            pattern_3sym_2col_keys.append(k)"
   ],
   "id": "2e52048889c4dd06",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:31.349360Z",
     "start_time": "2026-01-15T14:04:31.347131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets_path_L = os.path.join(db_L_dir, \"datasets\", \"01_expv1\")\n",
    "datasets_path_S = os.path.join(db_S_dir, \"datasets\", \"01_expv1\")\n",
    "datasets_path_M = os.path.join(db_M_dir, \"datasets\", \"01_expv1\")\n",
    "datasets_path_XS = os.path.join(db_XS_dir, \"datasets\", \"01_expv1\")\n"
   ],
   "id": "e3bad93fe4bc7d0d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:31.865849Z",
     "start_time": "2026-01-15T14:04:31.395846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_pattern_exactly_1_time_exclude_more, \\\n",
    "    generic_rule_N_times_color_shape_exactly, generic_rule_shape_in_every_row\n",
    "\n",
    "rules_data_L = [\n",
    "\n",
    "    {\"name\": \"hard1_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_L,\n",
    "                                                                                                                   \"y_division_full\": Y_DIVISIONS_L,\n",
    "                                                                                                                   \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                                   \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                                   \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.85, \"shown_acc\" : 0.85, \"samples_interface\": 13, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[0]},\n",
    "\n",
    "\n",
    "    {\"name\": \"hard3_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_L,\n",
    "                                                                                                                   \"y_division_full\": Y_DIVISIONS_L,\n",
    "                                                                                                                   \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                                   \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                                   \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.85, \"shown_acc\" : 0.85, \"samples_interface\": 13, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[1]},\n",
    "\n",
    "]"
   ],
   "id": "7f91986503f660c7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:31.873384Z",
     "start_time": "2026-01-15T14:04:31.870191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_pattern_exactly_1_time_exclude_more, \\\n",
    "    generic_rule_N_times_color_shape_exactly\n",
    "\n",
    "rules_data_S = [\n",
    "\n",
    "    # {\"name\": \"easy1_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_S,\n",
    "    #                                                                                                                \"y_division_full\": Y_DIVISIONS_S,\n",
    "    #                                                                                                                \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "    #                                                                                                                \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "    #                                                                                                                \"consider_rotations\": True},\n",
    "    #  \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.85, \"shown_acc\" : 0.85, \"samples_interface\": 6, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[4]},\n",
    "\n",
    "    {\"name\": \"easy3_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_S,\n",
    "                                                                                                                   \"y_division_full\": Y_DIVISIONS_S,\n",
    "                                                                                                                   \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                                   \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                                   \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.85, \"shown_acc\" : 0.85, \"samples_interface\": 6, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[5]},\n",
    "\n",
    "]"
   ],
   "id": "eb05007dbc4dc9fc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:31.925043Z",
     "start_time": "2026-01-15T14:04:31.921730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_pattern_exactly_1_time_exclude_more, \\\n",
    "    generic_rule_N_times_color_shape_exactly\n",
    "rules_data_M = [\n",
    "\n",
    "    {\"name\": \"med1_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_M,\n",
    "                                                                                                                  \"y_division_full\": Y_DIVISIONS_M,\n",
    "                                                                                                                  \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                                  \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                                  \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.85, \"shown_acc\" : 0.85, \"samples_interface\": 13, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[2]},\n",
    "\n",
    "    {\"name\": \"med3_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_M,\n",
    "                                                                                                                  \"y_division_full\": Y_DIVISIONS_M,\n",
    "                                                                                                                  \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                                  \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                                  \"consider_rotations\": True,\n",
    "                                                                                                                  },\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.85, \"shown_acc\" : 0.85, \"samples_interface\": 13, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[3]},\n",
    "\n",
    "    # {\"name\": \"med5_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_M,\n",
    "    #                                                                                                               \"y_division_full\": Y_DIVISIONS_M,\n",
    "    #                                                                                                               \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "    #                                                                                                               \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "    #                                                                                                               \"consider_rotations\": True,\n",
    "    #                                                                                                               },\n",
    "    #  \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.85, \"shown_acc\" : 0.85, \"samples_interface\": 13, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[6]},\n",
    "\n",
    "\n",
    "]\n"
   ],
   "id": "32dcf505eda62f7a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:31.973892Z",
     "start_time": "2026-01-15T14:04:31.971314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.datagen.gendataset import generic_rule_pattern_exactly_1_time_exclude_more, \\\n",
    "    generic_rule_N_times_color_shape_exactly, generic_rule_shape_in_every_row\n",
    "\n",
    "rules_data_XS = [\n",
    "    {\"name\": \"xeasy1_find_pattern_rot\", \"gen_fun\": generic_rule_pattern_exactly_1_time_exclude_more, \"gen_kwargs\": {\"x_division_full\": X_DIVISIONS_XS,\n",
    "                                                                                                                    \"y_division_full\": Y_DIVISIONS_XS,\n",
    "                                                                                                                    \"x_division_pattern\": X_DIVISIONS_PATTERNS,\n",
    "                                                                                                                    \"y_division_pattern\": Y_DIVISIONS_PATTERNS,\n",
    "                                                                                                                    \"consider_rotations\": True},\n",
    "     \"question\": \"Is the pattern or any of its left or right rotations in the image?\", \"target_acc\" : 0.5, \"shown_acc\" : 0.5, \"samples_interface\": 6, \"pos_llm_scaffold\": \"\", \"neg_llm_scaffold\": \"\", \"pattern_id\": pattern_3sym_2col_keys[7]},\n",
    "\n",
    "]"
   ],
   "id": "e0f09a11ef5bd7b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:35.437137Z",
     "start_time": "2026-01-15T14:04:32.018857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xaipatimg.ml.xai import generate_shap_resnet, generate_counterfactuals_resnet_random_approach, \\\n",
    "    create_xai_index, generate_cam_resnet18\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def generate_explanations(rules_data, db_dir, datasets_dir_path):\n",
    "    for rule_idx in tqdm(range(len(rules_data))):\n",
    "\n",
    "        model_dir = os.path.join(model_dir_root, rules_data[rule_idx][\"name\"])\n",
    "        dataset_filename = rules_data[rule_idx][\"name\"] + \"_test.csv\"\n",
    "        generic_rule_fun = rules_data[rule_idx][\"gen_fun\"]\n",
    "        generic_rule_fun_kwargs = rules_data[rule_idx][\"gen_kwargs\"]\n",
    "        xai_output_paths = {\n",
    "            \"shap\": \"shap\",\n",
    "            \"cf\": \"cf\",\n",
    "            \"gradcam\": \"gradcam\"\n",
    "        }\n",
    "\n",
    "        if \"pattern_id\" in rules_data[rule_idx]:\n",
    "            generic_rule_fun_kwargs[\"pattern_content\"] = db_patterns[rules_data[rule_idx][\"pattern_id\"]][\"cnt\"]\n",
    "\n",
    "        # generate_shap_resnet(os.path.join(db_dir, \"min/\"), datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "        #                      model_dir=model_dir, xai_output_path=os.path.join(model_dir, xai_output_paths[\"shap\"]),\n",
    "        #                      yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path, device=\"cuda:0\",\n",
    "        #                      n_jobs=N_JOBS,\n",
    "        #                      dataset_size=XAI_DATASET_SIZE, masker=\"ndarray\", shap_scale_img_path=shap_scale_img_path,\n",
    "        #                      resnet_type=RESNET_TYPE)\n",
    "\n",
    "        generate_counterfactuals_resnet_random_approach(os.path.join(db_dir, \"min/\"), datasets_dir_path=datasets_dir_path,\n",
    "                                                        dataset_filename=dataset_filename,\n",
    "                                                        model_dir=model_dir,\n",
    "                                                        xai_output_path=os.path.join(model_dir, xai_output_paths[\"cf\"]),\n",
    "                                                        yes_pred_img_path=yes_pred_img_path,\n",
    "                                                        no_pred_img_path=no_pred_img_path,\n",
    "                                                        shapes=SHAPES, colors=COLORS, empty_probability=1 - SHAPE_PROB,\n",
    "                                                        max_depth=10, nb_tries_per_depth=2000,\n",
    "                                                        generic_rule_fun=generic_rule_fun,\n",
    "                                                        devices=[\"cuda:0\", \"cuda:1\"], n_jobs=N_JOBS_GPU,\n",
    "                                                        dataset_size=XAI_DATASET_SIZE,\n",
    "                                                        pos_pred_legend_path=pos_pred_legend_path,\n",
    "                                                        neg_pred_legend_path=neg_pred_legend_path,\n",
    "                                                        **generic_rule_fun_kwargs, resnet_type=RESNET_TYPE)\n",
    "\n",
    "        # generate_cam_resnet18(cam_technique=\"gradcam\",\n",
    "        #                       db_dir=os.path.join(db_dir, \"min/\"),\n",
    "        #                       xai_output_path=os.path.join(model_dir, xai_output_paths[\"gradcam\"]),\n",
    "        #                       datasets_dir_path=datasets_dir_path,\n",
    "        #                       dataset_filename=dataset_filename,\n",
    "        #                       model_dir=model_dir,\n",
    "        #                       yes_pred_img_path=yes_pred_img_path,\n",
    "        #                       no_pred_img_path=no_pred_img_path,\n",
    "        #                       dataset_size=XAI_DATASET_SIZE,\n",
    "        #                       device=\"cuda:0\")\n",
    "        #\n",
    "        # create_xai_index(os.path.join(db_dir, \"min/\"), datasets_dir_path=datasets_dir_path, dataset_filename=dataset_filename,\n",
    "        #                  model_dir=model_dir,\n",
    "        #                  xai_dirs=xai_output_paths, dataset_size=XAI_DATASET_SIZE, device=\"cuda:0\",\n",
    "        #                  resnet_type=RESNET_TYPE)\n"
   ],
   "id": "1154a6bd395d6a3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "460996986eb1d7b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:35.448494Z",
     "start_time": "2026-01-15T14:04:35.447090Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6ba985e1130be781",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:35.490658Z",
     "start_time": "2026-01-15T14:04:35.488700Z"
    }
   },
   "cell_type": "code",
   "source": "# generate_explanations(rules_data_S, db_S_dir, datasets_path_S)",
   "id": "644903ef0b300427",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:35.539615Z",
     "start_time": "2026-01-15T14:04:35.537945Z"
    }
   },
   "cell_type": "code",
   "source": "# generate_explanations(rules_data_L, db_L_dir, datasets_path_L)",
   "id": "3eb943b8bff1fb77",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:35.582546Z",
     "start_time": "2026-01-15T14:04:35.580587Z"
    }
   },
   "cell_type": "code",
   "source": "# generate_explanations(rules_data_M, db_M_dir, datasets_path_M)",
   "id": "50fbe67227dcc32b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:35.630536Z",
     "start_time": "2026-01-15T14:04:35.628731Z"
    }
   },
   "cell_type": "code",
   "source": "# generate_explanations(rules_data_XS, db_XS_dir, datasets_path_XS)\n",
   "id": "4596ef4a5d3516ac",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:44.957893Z",
     "start_time": "2026-01-15T14:04:35.673066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import csv\n",
    "from xaipatimg.ml.xai import generate_LLM_explanations, create_xai_index\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_id = \"openai/gpt-oss-20b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "def gen_LLM_explanations(db_dir, rules_data, datasets_dir_path, X_divisions, Y_divisions):\n",
    "    db = load_db(os.path.join(db_dir, \"min/\"))\n",
    "\n",
    "    for rule_idx in tqdm(range(len(rules_data))):\n",
    "        model_dir = os.path.join(model_dir_root, rules_data[rule_idx][\"name\"])\n",
    "        dataset_filename = rules_data[rule_idx][\"name\"] + \"_test.csv\"\n",
    "\n",
    "        # Extracting the subset of indices of samples selected for the experimental interface, in order to ease the cost of calculation\n",
    "        interface_content_path = os.path.join(interface_dir, \"res\", \"tasks\",\n",
    "                                              f\"{rules_data[rule_idx][\"name\"]}_content.csv\")\n",
    "        interface_selected_idx = [int(row[\"og_idx\"]) for row in\n",
    "                                  list(csv.DictReader(open(interface_content_path), delimiter=','))]\n",
    "\n",
    "        xai_output_paths = {\n",
    "            \"shap\": \"shap\",\n",
    "            \"cf\": \"cf\",\n",
    "            \"gradcam\": \"gradcam\",\n",
    "            \"llm\": \"llm\",\n",
    "        }\n",
    "        generate_LLM_explanations(os.path.join(db_dir, \"min/\"), db, datasets_dir_path=datasets_dir_path,\n",
    "                                  dataset_filename=dataset_filename,\n",
    "                                  model_dir=model_dir, llm_model=llm_model, llm_tokenizer=tokenizer,\n",
    "                                  xai_output_path=os.path.join(model_dir, xai_output_paths[\"llm\"]),\n",
    "                                  question=rules_data[rule_idx][\"question\"],\n",
    "                                  yes_pred_img_path=yes_pred_img_path, no_pred_img_path=no_pred_img_path,\n",
    "                                  yes_pred_img_path_small=yes_small_pred_img_path,\n",
    "                                  no_pred_img_path_small=no_small_pred_img_path,\n",
    "                                  X_division=X_divisions, Y_division=Y_divisions,\n",
    "                                  device=\"cuda:0\", dataset_size=XAI_DATASET_SIZE,\n",
    "                                  # only_for_index=interface_selected_idx,\n",
    "                                  only_for_index=[30],\n",
    "                                  path_to_counterfactuals_dir_for_model_errors=os.path.join(model_dir,\n",
    "                                                                                            xai_output_paths[\"cf\"]),\n",
    "                                  pos_llm_scaffold=rules_data[rule_idx][\"pos_llm_scaffold\"],\n",
    "                                  neg_llm_scaffold=rules_data[rule_idx][\"neg_llm_scaffold\"],\n",
    "                                  pattern_dict=db_patterns[rules_data[rule_idx][\"pattern_id\"]][\"cnt\"] if \"pattern_id\" in\n",
    "                                                                                                             rules_data[rule_idx] else None,\n",
    "                                  resnet_type=RESNET_TYPE)\n",
    "\n",
    "        create_xai_index(os.path.join(db_dir, \"min/\"), dataset_filename=dataset_filename,\n",
    "                         datasets_dir_path=datasets_dir_path,\n",
    "                         model_dir=model_dir,\n",
    "                         xai_dirs=xai_output_paths, dataset_size=XAI_DATASET_SIZE, device=\"cuda:0\",\n",
    "                         resnet_type=RESNET_TYPE)\n"
   ],
   "id": "c418ac7342c2bf59",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 41 files: 100%|██████████| 41/41 [00:00<00:00, 182361.04it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Fetching 41 files: 100%|██████████| 41/41 [00:00<00:00, 213357.90it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:45.037858Z",
     "start_time": "2026-01-15T14:04:45.035704Z"
    }
   },
   "cell_type": "code",
   "source": "#gen_LLM_explanations(db_L_dir, rules_data_L, datasets_path_L, X_divisions=X_DIVISIONS_L, Y_divisions=Y_DIVISIONS_L)",
   "id": "3d72dcaaf6eae03d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a61bb2e60e115f7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:04:45.108747Z",
     "start_time": "2026-01-15T14:04:45.106859Z"
    }
   },
   "cell_type": "code",
   "source": "# gen_LLM_explanations(db_M_dir, rules_data_M, datasets_path_M, X_divisions=X_DIVISIONS_M, Y_divisions=Y_DIVISIONS_M)",
   "id": "55460a2e0354ec5c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:09:40.986736Z",
     "start_time": "2026-01-15T14:04:45.245541Z"
    }
   },
   "cell_type": "code",
   "source": "gen_LLM_explanations(db_S_dir, rules_data_S, datasets_path_S, X_divisions=X_DIVISIONS_S, Y_divisions=Y_DIVISIONS_S)",
   "id": "1f2b46b2badd40d5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Using cache found in /home/docker/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/docker/data/models/db3.2.0/01_expv1/easy3_find_pattern_rot/llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are the explainability system of an AI model. Your role is to justify the decisions of the model. The role of the model is to answer questions about the content of images of symbols of colors. The predictions of the model are always correct. The user will provide you the prediction of the AI model for a given image and the corresponding data. You need to give an explanation of the prediction. The explanation is expected to be a very short sentence which introduces a list of all coordinates that are involved in the model's prediction and which will be highlighted from your output. The justification sentence and the list of coordinates must be separated by the character '|'. The coordinates are separated with the symbol ';', and there is no need to sort them. Do not use escape characters or markdown syntax. The question the model must answer is 'Is the pattern or any of its left or right rotations in the image?'. The pattern to search for is 'A yellow square. Just on its bottom, a purple triangle. Just on its right, a yellow circle.'. The right rotation of the pattern is 'A yellow square. Just on its left, a purple triangle. Just on its bottom, a yellow circle.'. The left rotation is 'A yellow square. Just on its right, a purple triangle. Just on its top, a yellow circle.'  Here are examples of justifications for several samples. Positive detection of the pattern with no rotation : 'The pattern was found at the location highlighted below | (2,5);(3,5);(2,6)'. Positive detection of the right rotation of the pattern : 'The right rotation of the pattern was found at the location highlighted below.  | (2,5);(3,5);(2,6)'. Negative : 'The pattern was not found. Closest matches are highlighted below. | (2,5);(3,5);(4,6);(4,7)'. In case the sample is negative, only highlight close matches with two adjacent symbols of right color and shape (if there are any such matches). For any coordinate (X,Y), the X component describes the position on the left-right, and the Y component describes the position on the top-bottom axis. (0,0) is the top left corner.\n",
      "The AI model predicts Yes for the image : (0, 1) : blue triangle\n",
      "(0, 3) : blue square\n",
      "(0, 5) : blue square\n",
      "(0, 8) : yellow square\n",
      "(1, 1) : purple square\n",
      "(1, 2) : blue circle\n",
      "(1, 3) : purple triangle\n",
      "(1, 5) : yellow triangle\n",
      "(1, 6) : yellow circle\n",
      "(1, 8) : blue triangle\n",
      "(2, 0) : yellow square\n",
      "(2, 3) : yellow square\n",
      "(2, 4) : yellow circle\n",
      "(2, 5) : purple circle\n",
      "(2, 6) : blue square\n",
      "(2, 8) : yellow circle\n",
      "(3, 4) : blue circle\n",
      "(3, 7) : yellow square\n",
      "(3, 8) : yellow circle\n",
      "(4, 2) : yellow circle\n",
      "(4, 3) : purple circle\n",
      "(4, 5) : purple square\n",
      "(4, 6) : purple triangle\n",
      "(4, 7) : yellow circle\n",
      "(4, 8) : yellow square\n",
      "(5, 0) : blue circle\n",
      "(5, 3) : yellow square\n",
      "(5, 5) : purple circle\n",
      "(5, 6) : yellow circle\n",
      "(5, 8) : purple square\n",
      "(6, 0) : purple square\n",
      "(6, 1) : yellow triangle\n",
      "(6, 4) : blue square\n",
      "(6, 5) : blue triangle\n",
      "(6, 7) : yellow triangle\n",
      "(7, 0) : purple circle\n",
      "(7, 1) : yellow triangle\n",
      "(7, 4) : purple triangle\n",
      "(7, 5) : purple square\n",
      "(7, 6) : blue triangle\n",
      "(8, 0) : blue triangle\n",
      "(8, 1) : blue square\n",
      "(8, 3) : purple circle\n",
      "(8, 5) : yellow square\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [04:36<00:00, 276.97s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|channel|>analysis<|message|>We need to provide explanation: coordinates involved in model prediction. The prediction is Yes: meaning pattern found. Pattern: 'A yellow square. Just on its bottom, a purple triangle. Just on its right, a yellow circle.'\n",
      "\n",
      "We need to find coordinates that match this pattern in the image data. Let's parse the dataset: Each line has coordinate (X,Y): shape.\n",
      "\n",
      "Coordinate system: X is left-right, Y is top-bottom. So leftmost X = 0. Coordinates like (x,y).\n",
      "\n",
      "We need to identify a yellow square with its bottom adjacent to a purple triangle, and right adjacent a yellow circle. Adjacent means directly below? It says \"Just on its bottom\" meaning same X? \"Just on its right\" meaning same Y? The pattern examples earlier show coordinates like (2,5);(3,5);(2,6) for pattern found at location highlighted. Let's interpret that example: They listed 3 coordinates: (2,5) ; (3,5) ; (2,6). That suggests yellow square at (2,5), purple triangle at (3,5) (right?), yellow circle at (2,6) (bottom). But the pattern expected is square, purple triangle below, circle right. But the example shows triangle right and circle bottom. Hmm maybe coordinate mapping difference? Actually we need to check: In example \"The pattern was found...\" they had coordinates (2,5);(3,5);(2,6). They didn't say which is which but presumably (2,5) is the yellow square? Hard to say. But likely the first coordinate is the square, second coordinate the triangle, third coordinate the circle? But if triangle is right of square, that would be at (3,5) if square at (2,5). That matches. The circle is bottom at (2,6). So matches pattern: square at (2,5), triangle right at (3,5), circle bottom at (2,6). So pattern coordinates as given: square at (x,y), triangle at (x+1,y), circle at (x,y+1). Good.\n",
      "\n",
      "Thus we need find a set of coordinates such that: \n",
      "- At (x,y) there is a yellow square\n",
      "- At (x+1, y) there is a purple triangle\n",
      "- At (x, y+1) there is a yellow circle\n",
      "\n",
      "Check dataset for such arrangement.\n",
      "\n",
      "Let's search manually:\n",
      "\n",
      "We'll scan coordinates:\n",
      "\n",
      "List by Y coordinate:\n",
      "\n",
      "Y=0:\n",
      "(0,1) blue triangle? Wait x=0,y=1. Actually y=1. Let's list:\n",
      "\n",
      "Better create mapping:\n",
      "\n",
      "I'll parse systematically.\n",
      "\n",
      "We have coordinates:\n",
      "\n",
      "(0,1): blue triangle\n",
      "(0,3): blue square\n",
      "(0,5): blue square\n",
      "(0,8): yellow square\n",
      "\n",
      "(1,1): purple square\n",
      "(1,2): blue circle\n",
      "(1,3): purple triangle\n",
      "(1,5): yellow triangle\n",
      "(1,6): yellow circle\n",
      "(1,8): blue triangle\n",
      "\n",
      "(2,0): yellow square\n",
      "(2,3): yellow square\n",
      "(2,4): yellow circle\n",
      "(2,5): purple circle\n",
      "(2,6): blue square\n",
      "(2,8): yellow circle\n",
      "\n",
      "(3,4): blue circle\n",
      "(3,7): yellow square\n",
      "(3,8): yellow circle\n",
      "\n",
      "(4,2): yellow circle\n",
      "(4,3): purple circle\n",
      "(4,5): purple square\n",
      "(4,6): purple triangle\n",
      "(4,7): yellow circle\n",
      "(4,8): yellow square\n",
      "\n",
      "(5,0): blue circle\n",
      "(5,3): yellow square\n",
      "(5,5): purple circle\n",
      "(5,6): yellow circle\n",
      "(5,8): purple square\n",
      "\n",
      "(6,0): purple square\n",
      "(6,1): yellow triangle\n",
      "(6,4): blue square\n",
      "(6,5): blue triangle\n",
      "(6,7): yellow triangle\n",
      "\n",
      "(7,0): purple circle\n",
      "(7,1): yellow triangle\n",
      "(7,4): purple triangle\n",
      "(7,5): purple square\n",
      "(7,6): blue triangle\n",
      "\n",
      "(8,0): blue triangle\n",
      "(8,1): blue square\n",
      "(8,3): purple circle\n",
      "(8,5): yellow square\n",
      "\n",
      "Ok.\n",
      "\n",
      "Need yellow square at (x,y). We'll locate all yellow squares:\n",
      "\n",
      "(0,8), (2,0), (2,3), (3,7), (4,8), (5,3), (8,5).\n",
      "\n",
      "Now for each yellow square, check if at (x+1,y) a purple triangle and at (x,y+1) a yellow circle.\n",
      "\n",
      "Let's go one by one.\n",
      "\n",
      "Yellow square at (0,8):\n",
      "Check (1,8): blue triangle not purple triangle. So no.\n",
      "\n",
      "Yellow square at (2,0):\n",
      "Check (3,0)? Not listed. There's no coordinate (3,0). So fails.\n",
      "\n",
      "Yellow square at (2,3):\n",
      "Check (3,3)? Not listed. No coordinate. So fails.\n",
      "\n",
      "Yellow square at (3,7):\n",
      "Check (4,7): yellow circle (should be purple triangle). So fails.\n",
      "\n",
      "Yellow square at (4,8):\n",
      "Check (5,8): purple square, not triangle. Not.\n",
      "\n",
      "Yellow square at (5,3):\n",
      "Check (6,3): nothing. No.\n",
      "\n",
      "Yellow square at (8,5):\n",
      "Check (9,5): none. So fails.\n",
      "\n",
      "Thus no pattern with that orientation. But note possibility of right rotation or left rotation.\n",
      "\n",
      "We also need to check right rotation: pattern \"A yellow square. Just on its left, a purple triangle. Just on its bottom, a yellow circle.\" This means at (x,y) yellow square, triangle at (x-1, y), circle at (x, y+1). We need to check coordinates with x-1.\n",
      "\n",
      "Similarly left rotation: \"A yellow square. Just on its right, a purple triangle. Just on its top, a yellow circle.\" Means triangle at (x+1, y), circle at (x, y-1).\n",
      "\n",
      "We need see if any orientation matches.\n",
      "\n",
      "Check for right rotation:\n",
      "\n",
      "For each yellow square, check (x-1,y) purple triangle, and (x,y+1) yellow circle.\n",
      "\n",
      "Let's evaluate each yellow square.\n",
      "\n",
      "1) (0,8): x-1 = -1 none. So fails.\n",
      "\n",
      "2) (2,0): Check (1,0)? there is no (1,0). So fails.\n",
      "\n",
      "3) (2,3): Check (1,3): purple triangle? Yes (1,3) purple triangle! Good. Check (2,4): yellow circle? Yes (2,4) yellow circle. So we have right rotation match at square (2,3), triangle (1,3), circle (2,4). So pattern found: square at 2,3; triangle left at 1,3; circle below at 2,4. That matches right rotation: Purple triangle left, circle bottom. Right rotation defined earlier: \"A yellow square. Just on its left, a purple triangle. Just on its bottom, a yellow circle.\" Exactly. So yes.\n",
      "\n",
      "Check other squares for left rotation perhaps but not needed.\n",
      "\n",
      "Thus the prediction \"Yes\". Need to highlight coordinates involved in model's prediction: those three coordinates: (2,3);(1,3);(2,4). According to examples, use coordinates separated by ';'.\n",
      "\n",
      "Provide justification sentence: \"The right rotation of the pattern was found at the location highlighted below. | (2,3);(1,3);(2,4)\" maybe like example. They used \"The right rotation of the pattern was found at the location highlighted below. | ...\" So we should adapt.\n",
      "\n",
      "The instruction: \"The justification sentence and the list of coordinates must be separated by the character '|'.\" So they expect \"The right rotation of the pattern was found at the location highlighted below. | (2,3);(1,3);(2,4)\". That matches example style. They had trailing period before '|'? Example: 'The right rotation of the pattern was found at the location highlighted below.  | (2,5);(3,5);(2,6)' Note there are double spaces before '|' maybe not required but we can have a single space. Should we include period? Example has period then space, then two spaces? Actually example: \"... below.  | (...\". They might have two spaces. But we can use single space. It's fine. We'll output: \"The right rotation of the pattern was found at the location highlighted below | (2,3);(1,3);(2,4)\"\n",
      "\n",
      "However earlier example had period. They used '... below.  | (2,5)...' but we can keep same.\n",
      "\n",
      "We don't need to sort coordinates.\n",
      "\n",
      "Return final answer.<|end|><|start|>assistant<|channel|>final<|message|>The right rotation of the pattern was found at the location highlighted below. | (2,3);(1,3);(2,4)<|return|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using cache found in /home/docker/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/docker/anaconda3/envs/Pytorch_exp/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 1/1 [04:51<00:00, 291.95s/it]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:09:41.086445Z",
     "start_time": "2026-01-15T14:09:41.083746Z"
    }
   },
   "cell_type": "code",
   "source": "# gen_LLM_explanations(db_XS_dir, rules_data_XS, datasets_path_XS, X_divisions=X_DIVISIONS_XS, Y_divisions=Y_DIVISIONS_XS)",
   "id": "7428cc331e4ccf0d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:09:41.127173Z",
     "start_time": "2026-01-15T14:09:41.125478Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9e5944781673aa5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:09:41.189153Z",
     "start_time": "2026-01-15T14:09:41.187366Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36c05605adf389ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-15T14:09:41.332714Z",
     "start_time": "2026-01-15T14:09:41.330988Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8b6513cc4329c4a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
